{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By Hattie Chung (contact: hchung@broadinstitute.org) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains helper functions used in all analysis notebooks (for both HeLa and mouse hippocampus data). Functions from this notebook are imported using nbimporter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import statsmodels.stats as sms\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from statannot import add_stat_annotation\n",
    "from plotnine import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_figs_to_bucket(fdir, gdir, wildcard='*'):\n",
    "    if type(fdir) is not str: \n",
    "        fdir = str(sc.settings.figdir)\n",
    "    fdir1 = fdir+'/'+wildcard\n",
    "    !gsutil -m cp $fdir1 $gdir\n",
    "    print('Copying complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data handling and merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_adt_and_gex(adt_pd, gex_ad, ab_list): \n",
    "    import time\n",
    "    start = time.time()\n",
    "    for cell_bc in gex_ad.obs.index:\n",
    "        bc = cell_bc\n",
    "        if bc in adt_pd.columns:\n",
    "            for ab in ab_list: \n",
    "                gex_ad.obs.at[cell_bc,ab] = adt_pd.loc[ab,bc]\n",
    "    end = time.time()\n",
    "    print('Merged GEX and ADT in %0.3f seconds' %(end-start) )\n",
    "    return gex_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mito_ncounts(ad, case='mouse'):\n",
    "    # calculate mitochondrial fraction\n",
    "    if case=='human': \n",
    "        mito_genes = ad.var_names.str.startswith('MT-') # human\n",
    "    if case=='hg19': \n",
    "        mito_genes = ad.var_names.str.startswith('hg19_MT-') # human\n",
    "    elif case=='mouse': \n",
    "        mito_genes = ad.var_names.str.startswith('mt-') #mouse\n",
    "    \n",
    "    ad.obs['frac_mito'] = np.sum(ad[:, mito_genes].X, axis=1).A1 / np.sum(ad.X, axis=1).A1\n",
    "\n",
    "    # add the total counts per cell as observations-annotation to adata\n",
    "    ad.obs['n_counts'] = ad.X.sum(axis=1).A1\n",
    "    return ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roundup(x, base=5):\n",
    "    import math\n",
    "    return int(math.ceil(x / float(base))) * base\n",
    "\n",
    "def round_decimals_up(number:float, decimals:int=2):\n",
    "    import math\n",
    "    \"\"\"\n",
    "    Returns a value rounded up to a specific number of decimal places.\n",
    "    \"\"\"\n",
    "    if not isinstance(decimals, int):\n",
    "        raise TypeError(\"decimal places must be an integer\")\n",
    "    elif decimals < 0:\n",
    "        raise ValueError(\"decimal places has to be 0 or more\")\n",
    "    elif decimals == 0:\n",
    "        return math.ceil(number)\n",
    "\n",
    "    factor = 10 ** decimals\n",
    "    return math.ceil(number * factor) / factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CITE normalizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_CITE(ad_obj, ab_list):    \n",
    "    import scipy\n",
    "    # normalize all CITE ab by doing ab+1 / hashtag_counts (inflated pseudocount)\n",
    "    for ab in ab_list: \n",
    "        # nADT\n",
    "        ab_x = (ad_obj.obs[ab]+1)/ad_obj.obs['hashtag_counts']\n",
    "        ad_obj.obs[ab+'_norm'] = ab_x\n",
    "        \n",
    "        # nCLR\n",
    "        geo_mean = scipy.stats.mstats.gmean(ab_x[~np.isnan(ab_x)])\n",
    "        ad_obj.obs[ab+'_nCLR'] = np.log(ab_x/geo_mean)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch specific CLR correction\n",
    "def CITE_binarize_by_batch(ad, ab, norm_type, thresh_map):\n",
    "    import scipy\n",
    "    ad.obs[ab+'_binary'] = 0\n",
    "    for batch in ad.obs.batch.cat.categories:\n",
    "        b_thresh = thresh_map[batch]\n",
    "        b_idx = ((ad.obs['batch']==batch) & (ad.obs[ab+'_'+norm_type]>=b_thresh))\n",
    "        ad.obs.loc[b_idx,ab+'_binary'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## subsetting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feat_values(ad, var_name, scaling='lognorm'): \n",
    "    if var_name in ad.obs.columns: \n",
    "        # obs variable\n",
    "        vals = list(ad.obs[var_name])\n",
    "    elif var_name in ad.var_names: \n",
    "        # gene variable\n",
    "        if scaling=='zscore':\n",
    "            vals = [float(i) for i in list(ad[:,var_name].layers['zscore'].toarray())]\n",
    "        elif scaling=='lognorm': \n",
    "            vals = [float(i) for i in list(ad[:,var_name].layers['counts'].toarray())]\n",
    "        elif scaling=='zscore_regressed': \n",
    "            vals = [float(i) for i in list(ad[:,var_name].X.toarray())]\n",
    "        elif scaling=='spliced': \n",
    "            vals = [float(i) for i in list(ad[:,var_name].layers['spliced'].toarray())]\n",
    "        elif scaling=='unspliced': \n",
    "            vals = [float(i) for i in list(ad[:,var_name].layers['unspliced'].toarray())]\n",
    "    return vals\n",
    "\n",
    "def get_linear_regression_stats(ad, xname, yname, scaling='lognorm'):\n",
    "    from scipy import stats\n",
    "\n",
    "    xvals = get_feat_values(ad, xname, scaling)\n",
    "    yvals = get_feat_values(ad, yname, scaling)\n",
    "    \n",
    "    m,b = np.polyfit(xvals, yvals, 1)\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(xvals, yvals)\n",
    "    print('Slope %.4f \\t R^2 %.4f \\t pval %.6f' %(slope, r_value**2, p_value) )\n",
    "    print(r_value**2)\n",
    "    print(p_value)\n",
    "    \n",
    "    plot_X = xvals\n",
    "    plot_Y = [m*x for x in xvals] + b\n",
    "    \n",
    "    return plot_X, plot_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regress_ncounts(ad): \n",
    "    sc.pp.normalize_total(ad)\n",
    "    sc.pp.log1p(ad)\n",
    "    ad.raw = ad\n",
    "    sc.pp.regress_out(ad, ['n_counts'])\n",
    "    sc.pp.scale(ad, max_value=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filtered_df(df, FC_cutoff): \n",
    "    for col in df.columns: \n",
    "            df.loc[(df[col].abs()<FC_cutoff), col] = np.NAN\n",
    "            \n",
    "    # drop rows with only NaN\n",
    "    nan_only_genes = (df.isnull().sum(axis=1)==df.shape[1])==True\n",
    "    bad_genes = (nan_only_genes[nan_only_genes]).index\n",
    "    df.drop(bad_genes, inplace=True)\n",
    "    return df\n",
    "    \n",
    "def get_mask_subbed_df(df, mask_val=-100): \n",
    "    # substitute with mask_val \n",
    "    mask = df.isnull()\n",
    "    subbed_df = df.fillna(mask_val)\n",
    "    return subbed_df\n",
    "\n",
    "def get_mask_dropped_df(df): \n",
    "    # drop mask values\n",
    "    dropped_df = np.ma.masked_invalid(df)\n",
    "    return dropped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_EX_neuron_broad_type(ad_in): \n",
    "    clusters = ad_in.obs.annot.cat.categories\n",
    "    ex_neurons = [cluster for cluster in clusters if cluster.startswith('Ex.')]\n",
    "#     astroglia = ['Astrocyte','Microglia']\n",
    "\n",
    "    adata_grouped = ad_in.copy()\n",
    "#     adata_grouped.obs['annot'].cat.add_categories(['EX_neuron','Astroglia'], inplace=True)\n",
    "    adata_grouped.obs['annot'].cat.add_categories(['EX_neuron'], inplace=True)\n",
    "    adata_grouped.obs.loc[ad_in.obs['annot'].isin(ex_neurons),'annot'] = 'EX_neuron'\n",
    "#     adata_grouped.obs.loc[ad_in.obs['annot'].isin(astroglia),'annot'] = 'Astroglia'\n",
    "\n",
    "    adata_grouped.obs['annot'].cat.remove_unused_categories(inplace=True)\n",
    "    return adata_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_EX_and_CA_subtypes(ad_in): \n",
    "    clusters = ad_in.obs.annot.cat.categories\n",
    "    ex_CA = [cluster for cluster in clusters if cluster.startswith('Ex.CA')]\n",
    "    ex_GC = [cluster for cluster in clusters if cluster.startswith('Ex.GranuleCell')]\n",
    "\n",
    "    ad_CT_grouped = ad_in.copy()\n",
    "\n",
    "    ad_CT_grouped.obs['annot'].cat.add_categories(['EX_CA','EX_GranuleCell'], inplace=True)\n",
    "    ad_CT_grouped.obs.loc[ad_in.obs['annot'].isin(ex_GC),'annot'] = 'EX_GranuleCell'\n",
    "    ad_CT_grouped.obs.loc[ad_in.obs['annot'].isin(ex_CA),'annot'] = 'EX_CA'\n",
    "\n",
    "    ad_CT_grouped.obs['annot'].cat.remove_unused_categories(inplace=True)\n",
    "    return ad_CT_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear model tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_model(form, dataframe, model_type):\n",
    "    import warnings\n",
    "    import numpy as np\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    if model_type=='OLS':\n",
    "        try: \n",
    "            mod = smf.ols(formula=form, \n",
    "                       data=dataframe).fit()\n",
    "        except np.linalg.LinAlgError as err:\n",
    "            if 'Singular matrix' in str(err):\n",
    "                return None\n",
    "    elif model_type=='GLM_NegBin': \n",
    "        try: \n",
    "            mod = smf.glm(formula=form, \n",
    "                       data=dataframe, \n",
    "                      family=sm.families.NegativeBinomial()).fit()\n",
    "        except np.linalg.LinAlgError as err:\n",
    "            if 'Singular matrix' in str(err):\n",
    "                return None\n",
    "    elif model_type=='mixedlm': \n",
    "        try: \n",
    "            mod = smf.mixedlm(form, dataframe, \n",
    "                          groups=dataframe['batch']).fit()\n",
    "        except np.linalg.LinAlgError as err:\n",
    "            if 'Singular matrix' in str(err):\n",
    "                return None\n",
    "    elif model_type=='mixedlm_regularized': \n",
    "        try: \n",
    "            mod = smf.mixedlm(form, dataframe, \n",
    "                          groups=dataframe['batch']).fit_regularized()\n",
    "        except np.linalg.LinAlgError as err:\n",
    "            if 'Singular matrix' in str(err):\n",
    "                return None\n",
    "    else: \n",
    "        print('Please enter valid model type')\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(ad, FORMULA, model_type, cluster_name, CITE, data_mode, \n",
    "              regress=False, scale=False, permute=False, min_obs=20):\n",
    "    import copy\n",
    "    from sklearn import preprocessing\n",
    "    \n",
    "    # subset cells based on cluster if needed\n",
    "    if cluster_name!='': \n",
    "        if cluster_name not in set(ad.obs['annot']):\n",
    "            print('Please enter valid cluster name')\n",
    "            return\n",
    "        else: \n",
    "            print('Subsetting cluster %s' %cluster_name)\n",
    "            ad_clust = ad[ad.obs['annot']==cluster_name].copy()\n",
    "    else: \n",
    "        print('Using full adata')\n",
    "        ad_clust = ad.copy()\n",
    "    \n",
    "    # only keep genes found in at least 20 cells\n",
    "    if (data_mode is 'lognorm') or (data_mode is 'zscore'): \n",
    "        counts_type='counts'\n",
    "    elif data_mode is 'spliced': \n",
    "        counts_type='spliced_counts' \n",
    "    elif data_mode is 'unspliced': \n",
    "        counts_type='unspliced_counts'\n",
    "    else: \n",
    "        print(data_mode)\n",
    "        \n",
    "    ad_clust = ad_clust[:, ad_clust.layers[counts_type].astype(bool).sum(axis=0)>min_obs].copy()\n",
    "    cells, genes = ad_clust.shape\n",
    "    print('Testing genes with min %i cells' %min_obs)\n",
    "    if genes>0:\n",
    "        print('Cluster %s with %i nuclei and %i genes' %(cluster_name,cells,genes))\n",
    "    else: \n",
    "        print('Not enough cells with %i genes, aborting cluster analysis' %genes)\n",
    "        return None, None\n",
    "    \n",
    "    \n",
    "    # regress out n_counts here, if need be\n",
    "    if regress: \n",
    "        regress_ncounts(ad_clust)\n",
    "    \n",
    "    # gather all variables \n",
    "    df = copy.deepcopy(ad_clust.obs)\n",
    "    df['log_ncounts'] = np.log(df['n_counts'])\n",
    "    print('min max log_ncounts %.3f, %.3f' %(min(df['log_ncounts']), max(df['log_ncounts'])) )\n",
    "    df['treatment'] = copy.deepcopy(ad_clust.obs['assignment'])\n",
    "    \n",
    "    if scale: \n",
    "        scale_cols = ['log_ncounts', 'log_hashtag_counts', 'cFos_nCLR', 'p65_nCLR', 'PU1_nCLR', 'NeuN_nCLR']\n",
    "        df[scale_cols] = preprocessing.scale(df[scale_cols])\n",
    "        \n",
    "    # initialize output dataframes\n",
    "    mod = None\n",
    "    start_idx = 0\n",
    "    while mod is None: \n",
    "        init_gene = ad_clust.var_names[start_idx]\n",
    "        df['Gene'] = get_feat_values(ad_clust, init_gene, scaling=data_mode)\n",
    "        mod = fetch_model(FORMULA, df, model_type)\n",
    "        start_idx+=1\n",
    "        \n",
    "    params = pd.DataFrame([], index=ad_clust.var_names, columns=mod.params.index)\n",
    "    pvals = pd.DataFrame([], index=ad_clust.var_names, columns=mod.pvalues.index)\n",
    "    \n",
    "    # run model\n",
    "    print('Running model for all genes')\n",
    "    start = time.time()\n",
    "    idx=0\n",
    "    for gene in ad_clust.var_names:\n",
    "        df['Gene'] = get_feat_values(ad_clust, gene, scaling=data_mode)\n",
    "        mod = fetch_model(FORMULA, df, model_type)\n",
    "        if not (mod is None):\n",
    "            params.loc[gene] = mod.params\n",
    "            pvals.loc[gene] = mod.pvalues\n",
    "        else: \n",
    "            continue\n",
    "            \n",
    "        idx+=1\n",
    "        if (idx%1000) == 0: print(idx)\n",
    "            \n",
    "    end = time.time()\n",
    "    print(end-start)\n",
    "                     \n",
    "    return params, pvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_two_partmodel(ad, FORM1, FORM2, model_type, cluster_name, data_mode, scale=False, min_obs=20):\n",
    "    import copy\n",
    "    from sklearn import preprocessing\n",
    "    \n",
    "    # subset cells based on cluster if needed\n",
    "    if cluster_name!='': \n",
    "        if cluster_name not in set(ad.obs['annot']):\n",
    "            print('Please enter valid cluster name')\n",
    "            return\n",
    "        else: \n",
    "            print('Subsetting cluster %s' %cluster_name)\n",
    "            ad_clust = ad[ad.obs['annot']==cluster_name].copy()\n",
    "    else: \n",
    "        print('Using full adata')\n",
    "        ad_clust = ad.copy()\n",
    "    \n",
    "    # only keep genes found in at least 20 cells\n",
    "    if (data_mode is 'lognorm') or (data_mode is 'zscore'): \n",
    "        counts_type='counts'\n",
    "    elif data_mode is 'spliced': \n",
    "        counts_type='spliced_counts' \n",
    "    elif data_mode is 'unspliced': \n",
    "        counts_type='unspliced_counts'\n",
    "    else: \n",
    "        print(data_mode)\n",
    "        \n",
    "    ad_clust = ad_clust[:, ad_clust.layers[counts_type].astype(bool).sum(axis=0)>=min_obs].copy()\n",
    "    cells, genes = ad_clust.shape\n",
    "    print('Testing genes with min %i cells' %min_obs)\n",
    "    if genes>0:\n",
    "        print('Cluster %s with %i nuclei and %i genes' %(cluster_name,cells,genes))\n",
    "    else: \n",
    "        print('Not enough cells with %i genes, aborting cluster analysis' %genes)\n",
    "        return None, None\n",
    "    \n",
    "    # gather all variables \n",
    "    df = copy.deepcopy(ad_clust.obs)\n",
    "    df['log_ncounts'] = np.log(df['n_counts'])\n",
    "    print('min max log_ncounts %.3f, %.3f' %(min(df['log_ncounts']), max(df['log_ncounts'])) )\n",
    "    df['treatment'] = copy.deepcopy(ad_clust.obs['assignment'])\n",
    "    \n",
    "    if scale: \n",
    "        scale_cols = ['log_ncounts', 'log_hashtag_counts', 'cFos_nCLR', 'p65_nCLR', 'PU1_nCLR', 'NeuN_nCLR']\n",
    "        df[scale_cols] = preprocessing.scale(df[scale_cols])\n",
    "\n",
    "    # initialize output dataframes\n",
    "    mod0 = None\n",
    "    start_idx = 0\n",
    "    while mod0 is None: \n",
    "        init_gene = ad_clust.var_names[start_idx]\n",
    "        df['Gene'] = get_feat_values(ad_clust, init_gene, scaling=data_mode)\n",
    "        mod0 = fetch_model(FORM1, df, model_type)\n",
    "\n",
    "        df['Resid'] = mod0.resid\n",
    "        mod = fetch_model(FORM2, df, model_type)\n",
    "\n",
    "        start_idx+=1\n",
    "        \n",
    "    params = pd.DataFrame([], index=ad_clust.var_names, columns=mod.params.index)\n",
    "    pvals = pd.DataFrame([], index=ad_clust.var_names, columns=mod.pvalues.index)\n",
    "    \n",
    "    # run model\n",
    "    print('Running model for all genes')\n",
    "    start = time.time()\n",
    "    idx=0\n",
    "    for gene in ad_clust.var_names: \n",
    "        df['Gene'] = get_feat_values(ad_clust, gene, scaling=data_mode)\n",
    "        mod0 = fetch_model(FORM1, df, model_type)\n",
    "        if not (mod0 is None):\n",
    "            df['Resid'] = mod0.resid\n",
    "            mod = fetch_model(FORM2, df, model_type)\n",
    "        \n",
    "            if not (mod is None):\n",
    "                params.loc[gene] = mod.params\n",
    "                pvals.loc[gene] = mod.pvalues\n",
    "            else: \n",
    "                continue\n",
    "        else: \n",
    "            continue\n",
    "        idx+=1\n",
    "        if (idx%1000) == 0: print(idx)\n",
    "    end = time.time()\n",
    "    print(end-start)\n",
    "                     \n",
    "    return params, pvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_twostep_linear_model(adata, FORM1, FORM2, run_str, cluster, model='mixedlm', run_mode='zscore', \n",
    "                     scale=False, run_repeat=False, min_obs=20):\n",
    "    import os\n",
    "    outdir = './write/%s_%s_%s' %(run_str, model, run_mode)\n",
    "    if not os.path.isdir(outdir): os.mkdir(outdir)\n",
    "        \n",
    "    # check for previous run results\n",
    "    params_file = '%s/params_%s.pickle' %(outdir, cluster.replace(' ',''))\n",
    "    pvals_file = '%s/pvals_%s.pickle' %(outdir, cluster.replace(' ',''))    \n",
    "\n",
    "    # execute run \n",
    "    if not os.path.isfile(params_file) or run_repeat:\n",
    "        print('Starting run...')\n",
    "        params, pvals = run_two_partmodel(adata, FORM1, FORM2, model_type=model, cluster_name=cluster, \n",
    "                                  data_mode=run_mode, scale=scale, min_obs=min_obs)\n",
    "        params.to_pickle(params_file)\n",
    "        pvals.to_pickle(pvals_file)\n",
    "\n",
    "    else: \n",
    "        print('Loading prior run result')\n",
    "        params = pd.read_pickle(params_file)\n",
    "        pvals = pd.read_pickle(pvals_file)\n",
    "        \n",
    "    print('%s model with %s for cluster %s' %(model, run_mode, cluster))\n",
    "    \n",
    "    return params, pvals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_linear_model(adata, FORM, tissue, cluster, antibody, model='OLS', run_mode='lognorm', \n",
    "                     run_repeat=False, regress=False, permute=False, scale=False, \n",
    "                     min_obs=20):  \n",
    "    import os\n",
    "    outdir = './write/%s_%s_%s' %(tissue, model, run_mode)\n",
    "    if not os.path.isdir(outdir): os.mkdir(outdir)\n",
    "        \n",
    "    if type(antibody) is list:\n",
    "        ab_prefix = 'all'\n",
    "    else: \n",
    "        ab_prefix = antibody\n",
    "\n",
    "    # check for previous run results\n",
    "    if permute: \n",
    "        params_file = '%s/%s_%s_params_permuted.pickle' %(outdir, cluster.replace(' ',''), ab_prefix)\n",
    "        pvals_file = '%s/%s_%s_pvals_permuted.pickle' %(outdir, cluster.replace(' ',''), ab_prefix)\n",
    "    else: \n",
    "        params_file = '%s/%s_%s_params.pickle' %(outdir, cluster.replace(' ',''), ab_prefix)\n",
    "        pvals_file = '%s/%s_%s_pvals.pickle' %(outdir, cluster.replace(' ',''), ab_prefix)    \n",
    "\n",
    "    # execute run \n",
    "    if not os.path.isfile(params_file) or run_repeat:\n",
    "        params, pvals = run_model(ad=adata, FORMULA=FORM, model_type=model, cluster_name=cluster, \n",
    "                                  CITE=antibody, data_mode=run_mode, regress=regress, scale=scale, \n",
    "                                  permute=permute, min_obs=min_obs)\n",
    "        if params is not None: \n",
    "            params.to_pickle(params_file)\n",
    "            pvals.to_pickle(pvals_file)\n",
    "\n",
    "    else: \n",
    "        print('Loading prior run result')\n",
    "        params = pd.read_pickle(params_file)\n",
    "        pvals = pd.read_pickle(pvals_file)\n",
    "        \n",
    "    print('Ran %s model with %s for cluster %s and CITE %s' %(model, run_mode, cluster, ab_prefix))\n",
    "    \n",
    "    return params, pvals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mixedlm_results_scaled(ad, run_name, cts_type, scale=True, run_repeat=False, min_obs=10, THRESHOLD=0.05): \n",
    "    # cts_type: 'lognorm' or 'unspliced' or 'zscore'\n",
    "\n",
    "    formula = 'Gene ~ log_ncounts + cFos_nCLR + p65_nCLR + PU1_nCLR + NeuN_nCLR + log_hashtag_counts'\n",
    "    antibodies = ['cFos_nCLR','p65_nCLR','PU1_nCLR','NeuN_nCLR']\n",
    "    \n",
    "    if run_name=='proteins_PBS': \n",
    "        RUN_STR = 'hippocampus_PBS_CITE_nCLR_scaled'\n",
    "        ad_run = ad[ad.obs['assignment']=='PBS']\n",
    "        plot_str = 'mixedlm_PBS_proteins_scaled'\n",
    "        \n",
    "    elif run_name=='proteins_KA': \n",
    "        RUN_STR = 'hippocampus_KA_CITE_nCLR_scaled'\n",
    "        ad_run = ad[ad.obs['assignment']=='KainicAcid']\n",
    "        plot_str = 'mixedlm_KA_proteins_scaled'\n",
    "        \n",
    "    elif run_name=='proteins_interaction': \n",
    "        formula = 'Gene ~ log_ncounts + cFos_nCLR*C(assignment) + p65_nCLR*C(assignment) + PU1_nCLR*C(assignment) + NeuN_nCLR*C(assignment) + log_hashtag_counts'\n",
    "        RUN_STR = 'hippocampus_by_cluster_interaction'\n",
    "        ad_run = ad\n",
    "        plot_str = 'mixedlm_by_cluster_interaction'\n",
    "        \n",
    "    elif run_name=='proteins_interaction_flipped': \n",
    "        formula = 'Gene ~ log_ncounts + cFos_nCLR*C(assignment) + p65_nCLR*C(assignment) + PU1_nCLR*C(assignment) + NeuN_nCLR*C(assignment) + log_hashtag_counts'\n",
    "        RUN_STR = 'hippocampus_by_cluster_interaction_flipped'\n",
    "        ad_run = ad\n",
    "        ad_run.obs['assignment'].cat.reorder_categories(['PBS','KainicAcid'], inplace=True)\n",
    "        plot_str = 'mixedlm_by_cluster_interaction'\n",
    "        \n",
    "    params, pvals = combine_model_across_cell_types(ad_run, antibodies, formula, \n",
    "                                    run_class=RUN_STR, model='mixedlm', run_mode=cts_type,\n",
    "                                    scale=scale,\n",
    "                                    run_repeat=run_repeat,\n",
    "                                    min_obs=min_obs)\n",
    "    \n",
    "    sig = dict.fromkeys(pvals.keys())\n",
    "    for variate in sig.keys(): \n",
    "        sig[variate] = get_significance_df(pvals[variate], \n",
    "                                           method='fdr_bh', alpha=THRESHOLD)\n",
    "        print(variate)\n",
    "        print(sig[variate].sum())\n",
    "        \n",
    "    return params, pvals, sig, plot_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_model_across_cell_types(ad, CITE, formula, run_class='HIP', clusters='all', \n",
    "                                    pretty_plot=False, model='OLS', run_mode='lognorm',\n",
    "                                    permute=False, regress=False, scale=False, run_repeat=False,\n",
    "                                    min_obs=20): \n",
    "\n",
    "    if clusters=='all': \n",
    "        clusters = ad.obs['annot'].cat.categories\n",
    "    \n",
    "    if type(min_obs) is int: \n",
    "        min_obs_dict = dict.fromkeys(clusters, min_obs)\n",
    "    else: \n",
    "        min_obs_dict = dict(zip(clusters, min_obs))\n",
    "        \n",
    "    # collect all significance and coeffs\n",
    "    cluster_params = {}\n",
    "    cluster_pvals = {}\n",
    "    cur_params = []\n",
    "    for clust in clusters: \n",
    "        print(clust)\n",
    "    \n",
    "        # run model \n",
    "        params, pvals = run_linear_model(ad, formula, run_class, clust, \n",
    "                                         antibody=CITE,\n",
    "                                         model=model, run_mode=run_mode, \n",
    "                                         run_repeat=run_repeat,\n",
    "                                        regress=regress, \n",
    "                                         scale=scale, \n",
    "                                        permute=permute,\n",
    "                                        min_obs=min_obs_dict[clust])\n",
    "        \n",
    "        # add to aggregate\n",
    "        if params is not None: \n",
    "            cluster_params[clust] = params\n",
    "            cluster_pvals[clust] = pvals\n",
    "            cur_params = params\n",
    "        # if no data for current cluster, remove\n",
    "        else: \n",
    "            clusters = clusters.drop(labels=[clust])\n",
    "\n",
    "    print(clusters)\n",
    "    # aggregated dataframes - one for each variate\n",
    "    variates = cur_params.columns\n",
    "    params_all = {}\n",
    "    pvals_all = {}\n",
    "    for var in variates: \n",
    "        var_param = aggregate_variate_dfs(cluster_params, var, clusters)\n",
    "        var_pval = aggregate_variate_dfs(cluster_pvals, var, clusters)\n",
    "        \n",
    "        params_all[var], pvals_all[var] = var_param, var_pval\n",
    "    \n",
    "    return params_all, pvals_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mixedlm_results_total_model(ad, run_name, cts_type, run_repeat=False, min_obs=20,\n",
    "                                     model_type='mixedlm', scale=False, THRESHOLD=0.05): \n",
    "    import pickle\n",
    "    \n",
    "    # cts_type: 'lognorm' or 'unspliced' or 'zscore'\n",
    "    \n",
    "    formula = 'Gene ~ log_ncounts + log_hashtag_counts + C(annot) + cFos_nCLR + p65_nCLR + PU1_nCLR + NeuN_nCLR'\n",
    "    antibodies = ['cFos_nCLR','p65_nCLR','PU1_nCLR','NeuN_nCLR']\n",
    "    \n",
    "    if run_name=='proteins_PBS': \n",
    "        RUN_STR = 'hippocampus_PBS_CITE_nCLR_cluster_term'\n",
    "        ad_run = ad[ad.obs['assignment']=='PBS']\n",
    "        plot_str = 'total_mixedlm_PBS'\n",
    "        \n",
    "    elif run_name=='proteins_KA': \n",
    "        RUN_STR = 'hippocampus_KA_CITE_nCLR_cluster_term'\n",
    "        ad_run = ad[ad.obs['assignment']=='KainicAcid']\n",
    "        plot_str = 'total_mixedlm_KA'\n",
    "    \n",
    "    elif run_name=='treatment_interaction': \n",
    "        formula = 'Gene ~ log_ncounts + log_hashtag_counts + C(annot)*C(assignment) + cFos_nCLR + p65_nCLR + PU1_nCLR + NeuN_nCLR'\n",
    "        RUN_STR = 'hippocampus_CITE_all_treatment_interaction'\n",
    "        ad_run = ad\n",
    "        plot_str = 'total_mixedlm_treatment_interaction'\n",
    "\n",
    "    elif run_name=='treatment_interaction_complete': \n",
    "        formula = 'Gene ~ log_ncounts + log_hashtag_counts + C(annot)*C(assignment) + cFos_nCLR*C(assignment) + p65_nCLR*C(assignment) + PU1_nCLR*C(assignment) + NeuN_nCLR*C(assignment)'\n",
    "        RUN_STR = 'hippocampus_CITE_all_treatment_interaction_complete'\n",
    "        ad_run = ad\n",
    "        plot_str = 'total_mixedlm_treatment_interaction'\n",
    "        \n",
    "    elif run_name=='treatment_interaction_complete_flipped': \n",
    "        formula = 'Gene ~ log_ncounts + log_hashtag_counts + C(annot)*C(assignment) + cFos_nCLR*C(assignment) + p65_nCLR*C(assignment) + PU1_nCLR*C(assignment) + NeuN_nCLR*C(assignment)'\n",
    "        RUN_STR = 'hippocampus_CITE_all_treatment_interaction_complete_flipped'\n",
    "        ad_run = ad\n",
    "        ad_run.obs['assignment'].cat.reorder_categories(['PBS','KainicAcid'], inplace=True)\n",
    "        plot_str = 'total_mixedlm_treatment_interaction'\n",
    "        \n",
    "    params, pvals = run_linear_model(ad_run, formula, RUN_STR, \n",
    "                                         '', antibodies, model=model_type, run_mode=cts_type, \n",
    "                                            scale=scale, min_obs=min_obs,\n",
    "                                         run_repeat=run_repeat, permute=False)\n",
    "\n",
    "    sig = get_significance_df(pvals, method='fdr_bh', alpha=THRESHOLD) #fdr_bh\n",
    "                        \n",
    "#     gene_frac = make_gene_frac_df(params['Intercept'], ad_run)\n",
    "    \n",
    "    return params, pvals, sig, plot_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_variate_dfs(df_dict, variate, clusts): \n",
    "    # gather all genes across all clusters\n",
    "    all_genes = []\n",
    "    for clust in clusts: \n",
    "        all_genes = np.union1d(all_genes, df_dict[clust]['Intercept'].index)\n",
    "\n",
    "    var_df = pd.DataFrame([], columns=clusts, index=all_genes)\n",
    "    for clust in clusts: \n",
    "        var_df[clust] = df_dict[clust][variate]\n",
    "    return var_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_model_across_clusters_two_step(ad, formula1, formula2, run_class='HIP', clusters='all', \n",
    "                                    model='mixedlm', run_mode='zscore', run_repeat=False,\n",
    "                                    scale=False, min_obs=20): \n",
    "\n",
    "    if clusters=='all': \n",
    "        clusters = ad.obs['annot'].cat.categories\n",
    "    \n",
    "    if type(min_obs) is int: \n",
    "        min_obs_dict = dict.fromkeys(clusters, min_obs)\n",
    "    else: \n",
    "        min_obs_dict = dict(zip(clusters, min_obs))\n",
    "        \n",
    "    # collect all significance and coeffs\n",
    "    cluster_params = {}\n",
    "    cluster_pvals = {}\n",
    "    for clust in clusters: \n",
    "        print(clust)\n",
    "    \n",
    "        # run model \n",
    "        \n",
    "        params, pvals = run_twostep_linear_model(ad, formula1, formula2, run_class, \n",
    "                                                 cluster=clust, run_repeat=run_repeat, \n",
    "                                                 scale=scale, min_obs=min_obs_dict[clust]) \n",
    "        \n",
    "        # add to aggregate\n",
    "        cluster_params[clust] = params\n",
    "        cluster_pvals[clust] = pvals\n",
    "        \n",
    "    # aggregated dataframes - one for each variate\n",
    "    variates = params.columns\n",
    "    params_all = {}\n",
    "    pvals_all = {}\n",
    "    for var in variates: \n",
    "        var_param = aggregate_variate_dfs(cluster_params, var, clusters)\n",
    "        var_pval = aggregate_variate_dfs(cluster_pvals, var, clusters)\n",
    "        \n",
    "        params_all[var], pvals_all[var] = var_param, var_pval\n",
    "        \n",
    "    return params_all, pvals_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## curating model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sig_gene_list_cluster(sig,params,var,clust):\n",
    "    clust_genes = params[var][clust].loc[sig[var][clust]].index\n",
    "    return clust_genes\n",
    "\n",
    "def get_sig_gene_list(sig,params,var):\n",
    "    sig_genes = dict.fromkeys(sig[var].columns)\n",
    "#     sig_params = dict.fromkeys(sig[var].columns)\n",
    "    for col in sig[var].columns: \n",
    "        cur_sig = sig[var][col]\n",
    "        sig_genes[col] = cur_sig.loc[cur_sig==True].index\n",
    "#         sig_params[col] = params[var]\n",
    "    return sig_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_sig_gene_lists_cluster(var1, sig1, params1, str1, \n",
    "                                 var2, sig2, params2, str2, \n",
    "                         colors=['#FC942D','#2765D9','#A337F0']): \n",
    "\n",
    "    color_map = {str1:colors[0], str2:colors[1], 'both':colors[2]} \n",
    "    \n",
    "    sig_genes = dict.fromkeys(sig1[var1].columns)\n",
    "    for clust in sig_genes.keys():\n",
    "        genes_df = pd.DataFrame([], columns=['gene','list','cluster'])\n",
    "\n",
    "        genes_1 = get_sig_gene_list_cluster(sig1, params1, var1, clust)\n",
    "        genes_2 = get_sig_gene_list_cluster(sig2, params2, var2, clust)\n",
    "\n",
    "        genes_both = list(np.intersect1d(genes_1, genes_2))\n",
    "\n",
    "        for g1 in genes_1: \n",
    "            if g1 not in genes_both: \n",
    "                genes_df = genes_df.append({'gene':g1,'list':str1,'cluster':clust}, ignore_index=True)\n",
    "        for g2 in genes_2: \n",
    "            if g2 not in genes_both: \n",
    "                genes_df = genes_df.append({'gene':g2,'list':str2,'cluster':clust}, ignore_index=True)\n",
    "        for gb in genes_both: \n",
    "            genes_df = genes_df.append({'gene':gb,'list':'both','cluster':clust}, ignore_index=True)\n",
    "\n",
    "        genes_df['color'] = genes_df['list'].map(color_map)\n",
    "        \n",
    "        # build df\n",
    "        sig_genes[clust] = genes_df\n",
    "    \n",
    "    return sig_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sig_gene_df_with_color(var, sig, params, desc): \n",
    "    if isinstance(sig, pd.DataFrame): \n",
    "        sig_genes = list(sig[sig[var]].index)\n",
    "    else: \n",
    "        genes = get_sig_gene_list(sig, params, var)\n",
    "        sig_genes = list(set([item for val in genes.values() for item in val]))\n",
    "    \n",
    "    genes_df = pd.DataFrame([], columns=['gene','list'])\n",
    "    for g in sig_genes: \n",
    "        genes_df = genes_df.append({'gene':g, 'list':desc}, ignore_index=True)        \n",
    "    genes_df['color'] = '#FC942D'\n",
    "    return genes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_sig_gene_lists(var1, sig1, params1, str1, var2, sig2, params2, str2, \n",
    "                         colors=['#FC942D','#2765D9','#A337F0']): \n",
    "    if isinstance(params1,dict):\n",
    "        genes_1 = get_sig_gene_list(sig1, params1, var1)\n",
    "        sig_genes_1 = list(set([item for val in genes_1.values() for item in val]))\n",
    "    else: \n",
    "        sig_genes_1 = list(sig1[sig1[var1]].index)\n",
    "        \n",
    "    if isinstance(params2,dict):\n",
    "        genes_2 = get_sig_gene_list(sig2, params2, var2)\n",
    "        sig_genes_2 = list(set([item for val in genes_2.values() for item in val]))\n",
    "    else: \n",
    "        sig_genes_2 = list(sig2[sig2[var2]].index)\n",
    "        \n",
    "    sig_genes_both = list(np.intersect1d(sig_genes_1, sig_genes_2))\n",
    "    \n",
    "    genes_df = pd.DataFrame([], columns=['gene','list'])\n",
    "    for g1 in sig_genes_1: \n",
    "        if g1 not in sig_genes_both: \n",
    "            genes_df = genes_df.append({'gene':g1, 'list':str1}, ignore_index=True)\n",
    "    for g2 in sig_genes_2: \n",
    "        if g2 not in sig_genes_both: \n",
    "            genes_df = genes_df.append({'gene':g2, 'list':str2}, ignore_index=True)\n",
    "    for gb in sig_genes_both: \n",
    "        genes_df = genes_df.append({'gene':gb, 'list':'both'}, ignore_index=True)\n",
    "        \n",
    "    color_map = {str1:colors[0], str2:colors[1], 'both':colors[2]} \n",
    "    genes_df['color'] = genes_df['list'].map(color_map)\n",
    "    return genes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorted_sig_genes(feat, param, pval, sig):\n",
    "    sig_genes = {}\n",
    "    for clust in sig[feat].columns: \n",
    "        param_clust = param[feat][clust].loc[~param[feat][clust].isnull()]\n",
    "        pval_clust = pval[feat][clust].loc[~pval[feat][clust].isnull()]\n",
    "        sig_clust = sig[feat][clust].loc[~sig[feat][clust].isnull()]\n",
    "\n",
    "        param_sorted = param_clust.sort_values(ascending=True)\n",
    "        sig_sorted = sig_clust[param_sorted.index]\n",
    "\n",
    "        # organize gene list\n",
    "        plot_df = pd.concat([param_sorted, sig_sorted, pd.Series(np.arange(0,len(param_sorted),1), \n",
    "                                                       index=param_sorted.index)], \n",
    "                              axis=1, keys=['param','sig', 'rank'])\n",
    "        sig_genes[clust] = plot_df[plot_df['sig']]\n",
    "    return sig_genes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readjust_sig_threshold(ad, clust, params, pvals, sig, min_obs=10, THRESHOLD=0.05): \n",
    "    import copy \n",
    "    \n",
    "    ad_clust = ad[ad.obs['annot']==clust]\n",
    "    genes_thresh = ad_clust[:,ad_clust.layers['counts'].astype(bool).sum(axis=0)>min_obs].var.index\n",
    "    \n",
    "    if isinstance(params, pd.DataFrame):\n",
    "        # global         \n",
    "        genes_thresh_sub = [g for g in params.index if g in genes_thresh]\n",
    "        params_copy = params.loc[genes_thresh_sub]\n",
    "        pvals_copy = pvals.loc[genes_thresh_sub]\n",
    "        pvals_copy.fillna(1, inplace=True)\n",
    "        \n",
    "        sig_copy = get_significance_df(pvals_copy, method='fdr_bh', alpha=THRESHOLD) \n",
    "\n",
    "    else: \n",
    "        # cluster specific\n",
    "        genes_thresh_sub = [g for g in params['Intercept'].index if g in genes_thresh]\n",
    "        print('Truncated %i genes to %i genes' %(params['Intercept'].shape[0], len(genes_thresh_sub)))\n",
    "        \n",
    "        params_copy = copy.deepcopy(params)\n",
    "        pvals_copy = copy.deepcopy(pvals)\n",
    "        sig_copy = copy.deepcopy(sig)\n",
    "        \n",
    "        for variate in sig_copy.keys(): \n",
    "#             print(variate)\n",
    "            params_copy[variate] = params_copy[variate].loc[genes_thresh_sub]\n",
    "            pvals_copy[variate] = pvals_copy[variate].loc[genes_thresh_sub]\n",
    "            sig_copy[variate] = sig_copy[variate].loc[genes_thresh_sub]\n",
    "#             pvals_copy[variate].fillna(1, inplace=True)\n",
    "        \n",
    "            sig_copy[variate] = get_significance_df(pvals_copy[variate], #.fillna(1), \n",
    "                                               method='fdr_bh', alpha=THRESHOLD) \n",
    "\n",
    "    return params_copy, pvals_copy, sig_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_significance_df(pvals, method='bonferroni', alpha=0.05): \n",
    "    import copy\n",
    "    import statsmodels.stats as sms\n",
    "    \n",
    "    df_sig = copy.deepcopy(pvals)\n",
    "    for col in pvals.columns: \n",
    "        cur_pvals = pvals[col]\n",
    "        NOT_NAN = ~cur_pvals.isnull()\n",
    "        sig, _, _, _ = sms.multitest.multipletests(cur_pvals.loc[NOT_NAN], \n",
    "                                                 method=method, alpha=alpha)\n",
    "        cur_sig = NOT_NAN.copy()\n",
    "        cur_sig.replace(True, False, inplace=True)\n",
    "        cur_sig.loc[NOT_NAN] = sig\n",
    "        df_sig[col] = cur_sig \n",
    "        \n",
    "    df_sig.fillna(False, inplace=True)\n",
    "    return df_sig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gene_frac(ad):\n",
    "    ad.var['gene_frac'] = np.sum(ad.layers['counts'].astype(bool), axis=0).A1 / (ad.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gene_frac_df(df, ad): \n",
    "    df_genefrac = df.copy()\n",
    "    for clust in df_genefrac.columns: \n",
    "        ad_clust = ad[ad.obs['annot']==clust].copy()\n",
    "        add_gene_frac(ad_clust)\n",
    "        df_genefrac[clust] = ad_clust.var['gene_frac']\n",
    "    return df_genefrac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dotplot_df(params, pvals, sig, df_frac, feat, THRESH, COEFF_THRESH=0): \n",
    "    \n",
    "    df_sig = sig[feat].loc[sig[feat].sum(axis=1)>=THRESH]\n",
    "    temp_params = params[feat].loc[df_sig.index] # 10/31\n",
    "    sig_genes = temp_params[(np.abs(temp_params[df_sig])>COEFF_THRESH).sum(axis=1)>=1].index # 10/31\n",
    "    print('%i genes meet thresh' %(len(sig_genes)) )\n",
    "    \n",
    "    df_sig = sig[feat].loc[sig_genes] # 10/31\n",
    "    df_coeff = params[feat].loc[sig_genes] # 10/31\n",
    "    df_pval = pvals[feat].loc[sig_genes] # 10/31\n",
    "    \n",
    "    clusters = df_sig.columns\n",
    "    col_list = ['gene', 'cluster', 'coefficient', 'neglog_pval', 'significant', 'fraction']\n",
    "    plot_df = pd.DataFrame([], columns=col_list)\n",
    "    for gene in df_coeff.index: \n",
    "        for clust in df_coeff.columns: \n",
    "            p = df_pval.loc[gene,clust]\n",
    "            if not np.isnan(p):\n",
    "                temp_row = pd.DataFrame([[gene, clust, \n",
    "                                          df_coeff.loc[gene, clust],\n",
    "                                          -np.log10(p), \n",
    "                                          df_sig.loc[gene, clust], \n",
    "                                          df_frac.loc[gene, clust] ] ], \n",
    "                                        columns=col_list)\n",
    "                plot_df = plot_df.append(temp_row, ignore_index=True)\n",
    "\n",
    "    plot_df['cluster'] = plot_df['cluster'].astype('category')\n",
    "    plot_df['cluster'].cat.reorder_categories(new_categories=clusters, inplace=True)\n",
    "    return plot_df, df_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_df_sig(df_list, feat, groups): \n",
    "    df_feat = [df[feat] for df in df_list]\n",
    "    feats_concat = pd.concat(df_feat, keys=groups, axis=1)\n",
    "    return feats_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_df_sig_multi_feats(df_list, feat_list, groups):\n",
    "    df_feat=[]\n",
    "    for df, feat in zip(df_list, feat_list): \n",
    "        df_feat.append(df[feat])\n",
    "    feats_concat = pd.concat(df_feat, keys=groups, axis=1)\n",
    "    return feats_concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_sig_genes(feat, sig_df, clusters='all'):\n",
    "    if clusters=='all': \n",
    "        clusters = sig_cell_type['Intercept'].columns\n",
    "        \n",
    "    sig_genes = []\n",
    "    for clust in clusters: \n",
    "        cur_sig = sig_df[feat][clust]\n",
    "        sig_genes.extend(list(sig_df[feat][sig_df[feat][clust]].index))\n",
    "    return list(set(sig_genes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rev_dict_list(mydict):\n",
    "    from collections import defaultdict\n",
    "\n",
    "    reversed_dict = defaultdict(list)\n",
    "    for key, values in mydict.items():\n",
    "        for val in values:\n",
    "            reversed_dict[val].append(key)\n",
    "    return reversed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_feats_clusters_NMF(clusters, sig_df, ad, HVGs, add_NMF_genes=True, remove_ribo=False, feats=['cFos_nCLR','p65_nCLR']): \n",
    "    \n",
    "    # merge genes associated with each feature\n",
    "    feat_genes_all = []\n",
    "    for feat in feats: \n",
    "        feat_genes = cluster_sig_genes(feat, sig_df, clusters)\n",
    "        feat_genes_all.extend(feat_genes)\n",
    "\n",
    "    DEGs = list(set(feat_genes_all))\n",
    "    \n",
    "    # add HVGs\n",
    "    if add_NMF_genes: \n",
    "        NMF_genes = list(np.union1d(DEGs, list(HVGs)))\n",
    "    else: \n",
    "        NMF_genes = list(HVGs)\n",
    "    \n",
    "    # remove highly expressed genes\n",
    "    remove_genes = ['Gm42418', 'Ttr', 'Fth1', 'Ptgds']\n",
    "    for g in remove_genes: \n",
    "        if g in NMF_genes: \n",
    "            NMF_genes.remove(g)\n",
    "\n",
    "    if remove_ribo: \n",
    "        NMF_genes = [g for g in NMF_genes if not g.startswith('Rpl')]\n",
    "        NMF_genes = [g for g in NMF_genes if not g.startswith('Rps')]\n",
    "    \n",
    "    NMF_genes = [g for g in NMF_genes if not g.endswith('Rik')]\n",
    "\n",
    "    if isinstance(sig_df, pd.DataFrame): \n",
    "        NMF_genes = [g for g in NMF_genes if g in sig_df.index]\n",
    "    else: \n",
    "        NMF_genes = [g for g in NMF_genes if g in sig_df['Intercept'].index]\n",
    "    NMF_genes = [g for g in NMF_genes if ad.var.loc[g,'means']>0]\n",
    "    \n",
    "    ad_NMF = ad[:,NMF_genes].copy()\n",
    "    \n",
    "#     ad_NMF, NMF_genes = get_cluster_genes_for_NMF(ad, clusters, DEGs, sig_df, remove_ribo=remove_ribo)\n",
    "\n",
    "    # set ad to use\n",
    "    ad_run = ad_NMF[ad_NMF.obs['annot'].isin(clusters)].copy()\n",
    "    \n",
    "    return ad_run, NMF_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def module_top_GO_terms(module_genes):\n",
    "    fields_to_keep = ['source','name','p_value','significant','description','term_size',\n",
    "                      'query_size','intersection_size']\n",
    "    GO_aggregate = pd.DataFrame([], columns=fields_to_keep+['module'])\n",
    "    for i in range(len(module_genes)): \n",
    "        module_i_GO = parse_GO_query(module_genes[str(i)], 'mmusculus', db_to_keep=['GO:BP','KEGG'])\n",
    "        df_i = module_i_GO[fields_to_keep].iloc[:5]\n",
    "        df_i['module'] = 'module%i' %i\n",
    "        GO_aggregate = GO_aggregate.append(df_i)\n",
    "    return GO_aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorted_module_genes(module_by_gene, module_num, genes, top_N): \n",
    "    module_n = module_by_gene[module_num,:]\n",
    "    idx = np.argsort(module_n)\n",
    "    idx_list = list(idx)\n",
    "    idx_list.reverse()\n",
    "    genes_sorted = genes[idx_list]\n",
    "    module_genes_sorted = module_n[idx_list]\n",
    "    \n",
    "    return module_genes_sorted, genes_sorted\n",
    "    \n",
    "def corr_gene_vs_module(ad, gene, module_scores): \n",
    "    from scipy.stats import pearsonr, spearmanr\n",
    "    return pearsonr(ad[:,gene].layers['zscore'].flatten(), module_scores)\n",
    "\n",
    "def corr_geneset_vs_module(ad, genes, module_scores): \n",
    "    from scipy.stats import pearsonr, spearmanr\n",
    "    Rs = []\n",
    "    for gene in genes: \n",
    "        R, pval = corr_gene_vs_module(ad, gene, module_scores)\n",
    "        Rs.append(R)\n",
    "    return Rs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corr_df(ad, module_genes): \n",
    "    DEG_df = pd.DataFrame(ad.layers['zscore'], index=ad.obs.index, columns=ad.var.index)\n",
    "    if isinstance(module_genes, dict): \n",
    "        top_module_genes = list(set([item for sublist in module_genes.values() for item in sublist]))\n",
    "    else: \n",
    "        top_module_genes = module_genes\n",
    "    DEG_df_sub = DEG_df[top_module_genes]\n",
    "    DEG_corr = DEG_df_sub.corr()\n",
    "    return DEG_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_coeffs_to_color(prot, coeffs, genes_color, max_val=0, cmap='Blues'): \n",
    "    \n",
    "    import matplotlib.cm as cm\n",
    "    import matplotlib.colors as mcolors\n",
    "\n",
    "    if max_val==0: \n",
    "        max_val = max([np.abs(c) for c in coeffs])\n",
    "        \n",
    "    norm = mcolors.Normalize(vmin=-max_val, vmax=max_val, clip=True)\n",
    "    mapper = cm.ScalarMappable(norm=norm, cmap=cmap) \n",
    "\n",
    "    for g, v in zip(coeffs.index, coeffs):\n",
    "        genes_color.loc[g,'%s_effect' %prot] = mcolors.to_hex(mapper.to_rgba(v))\n",
    "    return genes_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cell_type_coefficient(prot, sig, params, clusters): \n",
    "    if 'nCLR' in prot: \n",
    "        prot_nCLR = prot\n",
    "    else: \n",
    "        prot_nCLR = '%s_nCLR' %prot\n",
    "    \n",
    "    feat_sub = sig[prot_nCLR][sig[prot_nCLR][clusters].sum(axis=1)>0]\n",
    "    feat_coeffs = pd.DataFrame([],index=feat_sub.index, columns=['%s_effect' %prot])\n",
    "    for idx, row in feat_sub.iterrows(): \n",
    "        if sum(row)==1: \n",
    "            feat_coeffs.loc[idx] = float(params[prot_nCLR].loc[idx,row[row].index])\n",
    "        elif sum(row)>1:\n",
    "            feat_coeffs.loc[idx] = max(params[prot_nCLR].loc[idx,row[row].index])\n",
    "        else: \n",
    "            continue\n",
    "            \n",
    "    return feat_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct gene feature colors\n",
    "def gene_feat_colors_cluster(sig, params, top_module_genes, clusters, \n",
    "                             proteins=['p65','cFos'], colors=['PuOr','PiYG_r']): \n",
    "    \n",
    "    genes_color = pd.DataFrame('#ffffff',index=top_module_genes, \n",
    "                               columns=['%s_effect' %prot for prot in proteins])\n",
    "    \n",
    "    for prot in proteins:\n",
    "        if 'nCLR' in prot: \n",
    "            prot_nCLR = prot\n",
    "        else: \n",
    "            prot_nCLR = '%s_nCLR' %prot\n",
    "            \n",
    "        feat_sig_genes = sig[prot_nCLR][sig[prot_nCLR][clusters].sum(axis=1)>0].index\n",
    "        for g in genes_color.index: \n",
    "            if g in feat_sig_genes: \n",
    "                genes_color.loc[g, '%s_effect' %prot] = '#000000'\n",
    "\n",
    "#     colors = ['Purples','Greens']\n",
    "    \n",
    "    for prot, prot_color in zip(proteins, colors): \n",
    "        prot_coeffs = get_cell_type_coefficient(prot, sig, params, clusters)\n",
    "        genes_sig_with_prot = genes_color[genes_color['%s_effect' %prot]!='#bfbfbf'].index\n",
    "        prot_coeffs = prot_coeffs.loc[np.intersect1d(genes_sig_with_prot,list(prot_coeffs.index))]\n",
    "        genes_color = map_coeffs_to_color(prot, prot_coeffs['%s_effect' %prot], genes_color, \n",
    "                                          max_val=0.1, cmap=prot_color)\n",
    "        \n",
    "    return genes_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_DEGs_modules(mxg, cxm, params, sig, feat, ad, cell_type=''): \n",
    "    mod_genes = mxg.columns\n",
    "    if isinstance(params, pd.DataFrame): \n",
    "        lm_genes = params.index\n",
    "        params_type = 'df'\n",
    "    else: \n",
    "        lm_genes = params['Intercept'].index\n",
    "        params_type = 'dict'\n",
    "    \n",
    "    modules = mxg.index\n",
    "    both_genes = np.intersect1d(mod_genes, lm_genes)\n",
    "    df = pd.DataFrame([], index=both_genes, columns=modules)\n",
    "    \n",
    "    for mod in modules: \n",
    "        df['%s_corr' %mod] = corr_geneset_vs_module(ad, df.index, cxm[mod])\n",
    "        if params_type=='df': \n",
    "            df['params'] = params.loc[both_genes, feat]\n",
    "            df['sig'] = sig.loc[both_genes, feat]\n",
    "        elif params_type=='dict': \n",
    "            df['params'] = params[feat].loc[both_genes,cell_type]\n",
    "            df['sig'] = sig[feat].loc[both_genes,cell_type]\n",
    "            \n",
    "    df_boxplot = pd.DataFrame([], columns=['gene','module','corr','sig','params'])\n",
    "    for idx, row in df.iterrows(): \n",
    "        for mod in modules: \n",
    "            df_boxplot = df_boxplot.append({'gene':idx,\n",
    "                                        'module':mod,\n",
    "                                        'corr':row['%s_corr' %mod],\n",
    "                                        'sig':row['sig'],\n",
    "                                        'params':row['params']}, \n",
    "                                        ignore_index=True)\n",
    "    return df, df_boxplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plotting tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## comparing UMI and gene counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_UMI_genes_hist(ad, samplestr, density=True, savefig=True): \n",
    "    from scipy.stats import gaussian_kde\n",
    "\n",
    "    # definitions for the axes\n",
    "    left, width = 0.1, 0.65\n",
    "    bottom, height = 0.1, 0.65\n",
    "    spacing = 0.005\n",
    "\n",
    "    rect_scatter = [left, bottom, width, height]\n",
    "    rect_histx = [left, bottom + height + spacing, width, 0.2]\n",
    "    rect_histy = [left + width + spacing, bottom, 0.2, height]\n",
    "\n",
    "    h = plt.figure(figsize=(3,3), dpi=1200)\n",
    "\n",
    "    ax_scatter = plt.axes(rect_scatter)\n",
    "    ax_scatter.tick_params(direction='in', top=True, right=True)\n",
    "    ax_histx = plt.axes(rect_histx)\n",
    "    ax_histx.tick_params(direction='in', labelbottom=False)\n",
    "    ax_histy = plt.axes(rect_histy)\n",
    "    ax_histy.tick_params(direction='in', labelleft=False)\n",
    "\n",
    "    # plot x=y line\n",
    "    ax_scatter.plot([0,6],[0,6],'k--',linewidth=1)\n",
    "    \n",
    "    x = np.log10(ad.obs['n_counts'])\n",
    "    y = np.log10(ad.obs['n_genes'])\n",
    "    \n",
    "    # calculate density\n",
    "    if density: \n",
    "        xy = np.vstack([x,y])\n",
    "        z = gaussian_kde(xy)(xy)\n",
    "        ax_sc = ax_scatter.scatter(x, y, c=z, s=3, alpha=0.5, cmap='coolwarm')\n",
    "#         plt.colorbar(ax_sc)\n",
    "    \n",
    "    else: \n",
    "\n",
    "        ax_scatter.scatter(x, y, s=3, color='#696969', alpha=0.5)\n",
    "    \n",
    "    bins = np.arange(0,6,0.1)\n",
    "    ax_histx.hist(x, bins=bins, facecolor='#696969')\n",
    "    ax_histy.hist(y, bins=bins, orientation='horizontal', facecolor='#696969')\n",
    "\n",
    "    # set axis properties \n",
    "    ax_scatter.set_xlim([1,5.1])\n",
    "    ax_scatter.set_xticks([1,2,3,4,5])\n",
    "    ax_scatter.set_xticklabels([1,2,3,4,5])\n",
    "    ax_scatter.set_ylim([1,4.5])\n",
    "    ax_scatter.set_yticks([1,2,3,4])\n",
    "    ax_scatter.set_xlabel('UMIs', fontsize=14)\n",
    "    ax_scatter.set_ylabel('Genes', fontsize=14)\n",
    "    \n",
    "    ax_histx.set_xlim(ax_scatter.get_xlim())\n",
    "    ax_histy.set_ylim(ax_scatter.get_ylim())\n",
    "    \n",
    "    ax_histx.spines['top'].set_visible(False)\n",
    "    ax_histx.spines['right'].set_visible(False)\n",
    "    ax_histx.spines['left'].set_visible(False)\n",
    "    ax_histx.set_xticks([])\n",
    "    ax_histx.set_yticks([])\n",
    "    \n",
    "    ax_histy.spines['top'].set_visible(False)\n",
    "    ax_histy.spines['right'].set_visible(False)\n",
    "    ax_histy.spines['bottom'].set_visible(False)\n",
    "    ax_histy.set_xticks([])\n",
    "    ax_histy.set_yticks([])\n",
    "\n",
    "    if savefig: \n",
    "        plt.savefig('%s/scatter_ngenes_UMIs_hist_%s.png' %(sc.settings.figdir, samplestr), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cluster proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_proportions(adata,\n",
    "                            cluster_key=\"leiden\",\n",
    "                            sample_key=\"batch\",\n",
    "                            drop_values=None):\n",
    "    \"\"\"\n",
    "    Input\n",
    "    =====\n",
    "    adata : AnnData object\n",
    "    cluster_key : key of `adata.obs` storing cluster info\n",
    "    sample_key : key of `adata.obs` storing sample/replicate info\n",
    "    drop_values : list/iterable of possible values of `sample_key` that you don't want\n",
    "    \n",
    "    Returns\n",
    "    =======\n",
    "    pd.DataFrame with samples as the index and clusters as the columns and 0-100 floats\n",
    "    as values\n",
    "    \"\"\"\n",
    "    \n",
    "    adata_tmp = adata.copy()\n",
    "    sizes = adata_tmp.obs.groupby([cluster_key, sample_key]).size()\n",
    "    props = sizes.groupby(level=1).apply(lambda x: 100 * x / x.sum()).reset_index() \n",
    "    props = props.pivot(columns=sample_key, index=cluster_key).T\n",
    "    props.index = props.index.droplevel(0)\n",
    "    props.fillna(0, inplace=True)\n",
    "    \n",
    "    if drop_values is not None:\n",
    "        for drop_value in drop_values:\n",
    "            props.drop(drop_value, axis=0, inplace=True)\n",
    "    return props\n",
    "\n",
    "\n",
    "def plot_cluster_proportions(cluster_props, \n",
    "                             cluster_palette=None,\n",
    "                             xlabel_rotation=0): \n",
    "    import seaborn as sns\n",
    "    fig, ax = plt.subplots(dpi=300)\n",
    "    fig.patch.set_facecolor(\"white\")\n",
    "    \n",
    "    cmap = None\n",
    "    if cluster_palette is not None:\n",
    "        cmap = sns.palettes.blend_palette(\n",
    "            cluster_palette, \n",
    "            n_colors=len(cluster_palette), \n",
    "            as_cmap=True)\n",
    "   \n",
    "    cluster_props.plot(\n",
    "        kind=\"bar\", \n",
    "        stacked=True, \n",
    "        ax=ax, \n",
    "        legend=None, \n",
    "        colormap=cmap\n",
    "    )\n",
    "    \n",
    "    ax.legend(bbox_to_anchor=(1.01, 1), frameon=False, title=\"Replicate / batch\")\n",
    "    sns.despine(fig, ax)\n",
    "    ax.tick_params(axis=\"x\", rotation=xlabel_rotation)\n",
    "    ax.set_xlabel(cluster_props.index.name.capitalize())\n",
    "    ax.set_ylabel(\"% of nuclei in cluster\")\n",
    "    ax.set_xticklabels(cluster_props.index, rotation = 90)\n",
    "    ax.set_yticks([0,50,100])\n",
    "    ax.set_yticklabels([0,50,100])\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## colormaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gray_monoscale_cmap(): \n",
    "    import matplotlib\n",
    "    from matplotlib import cm\n",
    "    blues = cm.get_cmap('Blues', 500)\n",
    "    blues_array = blues(np.linspace(0, 1, 15)).tolist()\n",
    "    blues_array.insert(0, [0.85, 0.85, 0.85, 1.0])\n",
    "    bg = matplotlib.colors.ListedColormap(blues_array,name='blues_with_gray')\n",
    "    return bg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_seismic_with_nan(): \n",
    "    import matplotlib\n",
    "    from matplotlib import cm\n",
    "    seismic = cm.get_cmap('seismic', 500)\n",
    "    seismic_array = seismic(np.linspace(0, 1, 499)).tolist()\n",
    "    seismic_array.insert(0, [0.85, 0.85, 0.85, 1.0])\n",
    "    sg = matplotlib.colors.ListedColormap(seismic_array,name='seismic_with_gray')\n",
    "    return sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_YlGn_colorbars(): \n",
    "    a = np.array([[0,1]])\n",
    "    plt.figure(figsize=(0.5, 5))\n",
    "    img = plt.imshow(a, cmap=\"YlGn\", vmin=0, vmax=0.8)\n",
    "    plt.gca().set_visible(False)\n",
    "    cax = plt.axes([0.1, 0.2, 0.8, 0.6])\n",
    "    plt.colorbar(orientation=\"vertical\", cax=cax)\n",
    "    figname = \"%s/YlGn_colorbar.pdf\" %sc.settings.figdir\n",
    "    print('Saving to %s' %figname)\n",
    "    plt.savefig(figname, bbox_inches='tight')\n",
    "\n",
    "    a = np.array([[0,1]])\n",
    "    plt.figure(figsize=(5, 0.5))\n",
    "    img = plt.imshow(a, cmap=\"YlGn\", vmin=0, vmax=0.8)\n",
    "    plt.gca().set_visible(False)\n",
    "    cax = plt.axes([0.1, 0.2, 0.6, 0.8])\n",
    "    plt.colorbar(orientation=\"horizontal\", cax=cax)\n",
    "    figname = \"%s/YlGn_colorbar_horizontal.pdf\" %sc.settings.figdir\n",
    "    print('Saving to %s' %figname)\n",
    "    plt.savefig(figname, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_vertical_colorbar(cm='coolwarm', vmin=-0.15, vmax=0.15): \n",
    "    a = np.array([[0,1]])\n",
    "    plt.figure(figsize=(0.5, 4))\n",
    "    img = plt.imshow(a, cmap=cm, vmin=vmin, vmax=vmax)\n",
    "    plt.gca().set_visible(False)\n",
    "    cax = plt.axes([0.1, 0.2, 0.8, 0.6])\n",
    "    plt.colorbar(orientation=\"vertical\", cax=cax)\n",
    "    figname = \"%s/%s_colorbar_vertical.pdf\" %(sc.settings.figdir, cm)\n",
    "    print('Saving to %s' %figname)\n",
    "    plt.savefig(figname, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_horizontal_colorbar(cm='coolwarm', vmin=-0.15, vmax=0.15): \n",
    "    a = np.array([[0,1]])\n",
    "    plt.figure(figsize=(5,0.5))\n",
    "    img = plt.imshow(a, cmap=cm, vmin=vmin, vmax=vmax)\n",
    "    plt.gca().set_visible(False)\n",
    "    cax = plt.axes([0.1, 0.2, 0.6, 0.8])\n",
    "    plt.colorbar(orientation=\"horizontal\", cax=cax)\n",
    "    figname = \"%s/%s_colorbar_horizontal.pdf\" %(sc.settings.figdir, cm)\n",
    "    print('Saving to %s' %figname)\n",
    "    plt.savefig(figname, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hex_to_rgb(value): \n",
    "    value = value.strip('#')\n",
    "    lv = len(value)\n",
    "    return tuple(int(value[i:i + lv // 3], 16) for i in range(0, lv, lv // 3)) \n",
    "\n",
    "def rgb_to_dec(value): \n",
    "    return [v/256 for v in value]\n",
    "\n",
    "def get_continuous_cmap(hex_list, map_name, float_list=None): \n",
    "    import matplotlib.colors as mcolors\n",
    "    rgb_list = [rgb_to_dec(hex_to_rgb(i)) for i in hex_list]\n",
    "    if float_list: \n",
    "        pass\n",
    "    else: \n",
    "        float_list = list(np.linspace(0,1,len(rgb_list)))\n",
    "    cdict = dict()\n",
    "    for num, col in enumerate(['red','green','blue']):\n",
    "        col_list = [[float_list[i], rgb_list[i][num], rgb_list[i][num]] for i in range(len(float_list))]\n",
    "        cdict[col] = col_list\n",
    "    cmp = mcolors.LinearSegmentedColormap(map_name, segmentdata=cdict, N=256)\n",
    "    return cmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## protein levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ab_lims(ab): \n",
    "    if ab=='NeuN_nCLR': \n",
    "        bins = np.arange(-2,2,0.05)\n",
    "        xlims = [-2,1.5]\n",
    "        batch_thresh = {'0':-0.2,\n",
    "                        '1':-0.11}\n",
    "    elif ab=='NeuN_CLR':\n",
    "        bins = np.arange(-3,2.5,0.05)\n",
    "        xlims = [-3,2.5]\n",
    "        batch_thresh = {'0':-1,\n",
    "                        '1':0}\n",
    "    elif ab=='cFos_nCLR': \n",
    "        bins = np.arange(-5,5,0.1)\n",
    "        xlims = [-3,3]\n",
    "        batch_thresh = {'0':0.1,\n",
    "                        '1':-0.65}\n",
    "    elif ab=='cFos_CLR': \n",
    "        bins = np.arange(-5,5,0.1)\n",
    "        xlims = [-2,2]\n",
    "        batch_thresh = {'0':-0.1,\n",
    "                        '1':-0.08}\n",
    "    elif ab=='p65_nCLR': \n",
    "        bins = np.arange(-2,3,0.05)\n",
    "        xlims = [-3,3.5]\n",
    "        batch_thresh = {'0':0.4,\n",
    "                        '1':0.75}\n",
    "    elif ab=='p65_CLR': \n",
    "        bins = np.arange(-5,5,0.1)\n",
    "        xlims = [-3,3]\n",
    "        batch_thresh = {'0':0.1,\n",
    "                        '1':1.25}\n",
    "        \n",
    "    elif ab=='PU1_nCLR':\n",
    "        bins = np.arange(-2,4,0.2)\n",
    "        xlims = [-2,3]\n",
    "        batch_thresh = {'0':0.85,\n",
    "                        '1':0.6}\n",
    "    \n",
    "    return xlims, bins, batch_thresh "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_disthist(vals, bins, color='#696969', alpha=0.5, kde_bw=0.2, kde_thresh=0.8, ax=None): \n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    ax = sns.distplot(vals, bins=bins, norm_hist=True, color=color,\n",
    "                        kde_kws={'bw':kde_bw,\n",
    "                                'thresh':kde_thresh},\n",
    "                         ax=ax)\n",
    "#     plt.xlim([min(bins),max(bins)])\n",
    "    axes = plt.axes(ax)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_linewidth(1.5)\n",
    "    ax.spines['left'].set_linewidth(1.5)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multi_mode(l): \n",
    "    from collections import Counter\n",
    "    from itertools import groupby\n",
    "\n",
    "    # group most_common output by frequency\n",
    "    freqs = groupby(Counter(l).most_common(), lambda x:x[1])\n",
    "    # pick off the first group (highest frequency)\n",
    "    return [val for val,count in next(freqs)[1]]\n",
    "    \n",
    "\n",
    "def plot_disthist_by_batch(ab, ad_fore, fore_c, ad_back, back_c, savefig=False, dotted_line=True): \n",
    "    \n",
    "    xlims, bins, b_thresh = get_ab_lims(ab)\n",
    "#     fig, (ax1, ax2, ax3) = plt.subplots(3, 1, sharex=True, figsize=(4,7))\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(4,5))\n",
    "    \n",
    "    plt.axes(ax1)\n",
    "    ab_b0 = ad_back[ad_back.obs['batch']=='0'].obs[ab]\n",
    "    ab_f0 = ad_fore[ad_fore.obs['batch']=='0'].obs[ab]\n",
    "    \n",
    "    normalized_disthist(      ab_b0, bins=bins, color=back_c, \n",
    "                             kde_bw=0.1, kde_thresh=10, alpha=0.7, ax=ax1)\n",
    "    ax1 = normalized_disthist(ab_f0, bins=bins, color=fore_c, \n",
    "                             kde_bw=0.1, kde_thresh=10, alpha=0.7, ax=ax1)\n",
    "    if dotted_line: \n",
    "        ax1.axvline(b_thresh['0'], color='k', linestyle='--', alpha=0.5)\n",
    "    ax1.set_xlim(xlims)\n",
    "    \n",
    "    plt.sca(ax2)\n",
    "    ab_b1 = ad_back[ad_back.obs['batch']=='1'].obs[ab]\n",
    "    ab_f1 = ad_fore[ad_fore.obs['batch']=='1'].obs[ab]\n",
    "    ax2 = normalized_disthist(ab_b1, bins=bins, color=back_c, \n",
    "                             kde_bw=0.1, kde_thresh=10, alpha=0.7, ax=ax2)\n",
    "    ax2 = normalized_disthist(ab_f1, bins=bins, color=fore_c, \n",
    "                             kde_bw=0.1, kde_thresh=10, alpha=0.7, ax=ax2)\n",
    "    if dotted_line: \n",
    "        ax2.axvline(b_thresh['1'], color='k', linestyle='--', alpha=0.5)\n",
    "    ax2.set_xlim(xlims)\n",
    "\n",
    "    \n",
    "    if savefig: \n",
    "        figname = '%s/distplot_%s_by_batch.pdf' %(sc.settings.figdir, ab)\n",
    "        print('Saving to %s' %figname)\n",
    "        fig.savefig(figname, bbox_inches='tight')\n",
    "\n",
    "def plot_disthist_single_batch(ab, ad_fore, fore_c, ad_back, back_c, batch, xlims=[], savefig=False, \n",
    "                               vertline=True, figstr='', kde_bw=0.1):\n",
    "    xlim_pre, bins, b_thresh = get_ab_lims(ab)\n",
    "    if len(xlims) == 0: \n",
    "        xlims = xlim_pre\n",
    "    \n",
    "    fig, ax1 = plt.subplots(figsize=(4,3))\n",
    "    plt.axes(ax1)\n",
    "    back_gr = ad_back[ad_back.obs['batch']==batch].obs[ab]\n",
    "    normalized_disthist(back_gr, bins=bins, color=back_c, \n",
    "                             kde_bw=kde_bw, kde_thresh=10, alpha=0.7, ax=ax1)\n",
    "    fore_gr = ad_fore[ad_fore.obs['batch']==batch].obs[ab]\n",
    "    ax1 = normalized_disthist(fore_gr, bins=bins, color=fore_c, \n",
    "                             kde_bw=kde_bw, kde_thresh=10, alpha=0.7, ax=ax1)\n",
    "    \n",
    "    if vertline:\n",
    "        ax1.axvline(b_thresh[batch], color='k', linestyle='--', alpha=0.5)\n",
    "        \n",
    "    ax1.set_xlim(xlims)\n",
    "    if savefig and figstr=='': \n",
    "        fig.savefig('%s/distplot_%s_batch%s.pdf' %(sc.settings.figdir, ab, batch), bbox_inches='tight')\n",
    "    elif savefig: \n",
    "        fig.savefig('%s/%s.pdf' %(sc.settings.figdir, figstr), bbox_inches='tight')\n",
    "        \n",
    "    # stats test\n",
    "    import scipy\n",
    "    stat, pval = scipy.stats.ttest_ind(back_gr,fore_gr)\n",
    "    print(pval, stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### boxplots - single protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_RNA_level_by_protein_bin(ad, gene, cite, scaling='lognorm', remove_zeros=False): \n",
    "    bin_name = cite+'_binary'\n",
    "    if remove_zeros: \n",
    "        if scaling=='lognorm' or scaling=='zscore': \n",
    "            feat_type='counts'\n",
    "        elif scaling=='spliced': \n",
    "            feat_type='spliced_counts'\n",
    "        elif scaling=='unspliced': \n",
    "            feat_type='unspliced_counts'\n",
    "        else: \n",
    "            feat_type=scaling\n",
    "        ad = ad[ad[:,gene].layers[feat_type].toarray()>0].copy()\n",
    "    \n",
    "    prot_neg = ad[ad.obs[bin_name]==0]\n",
    "    prot_pos = ad[ad.obs[bin_name]==1]\n",
    "    \n",
    "    RNA_neg = get_feat_values(prot_neg, gene, scaling)\n",
    "    RNA_pos = get_feat_values(prot_pos, gene, scaling)\n",
    "    \n",
    "    RNA_off_df = pd.DataFrame(list(zip(RNA_neg,len(RNA_neg)*['off'])),columns=[gene,'protein'])\n",
    "    RNA_on_df = pd.DataFrame(list(zip(RNA_pos,len(RNA_pos)*['on'])),columns=[gene,'protein'])\n",
    "    RNA_df = RNA_off_df.append(RNA_on_df,ignore_index=True)\n",
    "    \n",
    "    return RNA_neg, RNA_pos, RNA_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot_RNA_by_protein_bin(ad, gene, prot, color_dict, ylims=[0,11], desc='', scaling='zscore', \n",
    "                               remove_zeros=True):\n",
    "    from statannot import add_stat_annotation\n",
    "    if prot+'_binary' not in ad.obs.columns: \n",
    "        _,_,thresh = get_ab_lims(prot+'_nCLR')\n",
    "        CITE_binarize_by_batch(ad, prot, 'nCLR', thresh)\n",
    "    \n",
    "    RNA_off, RNA_on, RNA_df = get_RNA_level_by_protein_bin(ad, gene, prot,\n",
    "                                                            scaling=scaling, \n",
    "                                                            remove_zeros=remove_zeros)\n",
    "    fig, ax = plt.subplots(figsize=(2,3))\n",
    "    ax = sns.boxplot(data=RNA_df, x='protein', y=gene, \n",
    "                     order=['off','on'], width=0.3, \n",
    "                     palette=color_dict)\n",
    "    ax.set_ylim(ylims)\n",
    "    for patch in ax.artists:\n",
    "        r, g, b, a = patch.get_facecolor()\n",
    "        patch.set_facecolor((r, g, b, 0.5))\n",
    "        \n",
    "    ax = sns.stripplot(data=RNA_df, x='protein', y=gene, \n",
    "                       order=['off','on'], s=2, \n",
    "                       alpha=0.5, jitter=0.08,\n",
    "                       palette=color_dict)\n",
    "    test_results = add_stat_annotation(ax, data=RNA_df, x='protein', y=gene, \n",
    "                                       order=['off','on'],\n",
    "                                       box_pairs=[('off', 'on')],\n",
    "                                       test='t-test_ind', text_format='star',\n",
    "                                       loc='outside', verbose=2)\n",
    "    figname = '%s/boxplot_%s_%s_%s_%s.pdf' %(sc.settings.figdir, prot, gene, scaling, desc)\n",
    "    print('Saving to %s' %figname)\n",
    "    fig.savefig(figname, bbox_inches='tight')\n",
    "    \n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot_RNA_by_protein_bin_splicing(ad, gene, prot, color_dict, desc='', remove_zeros=True):\n",
    "    from statannot import add_stat_annotation\n",
    "    if prot+'_binary' not in ad.obs.columns: \n",
    "        _,_,thresh = get_ab_lims(prot+'_nCLR')\n",
    "        CITE_binarize_by_batch(ad, prot, 'nCLR', thresh)\n",
    "    \n",
    "    _, _, RNA_spliced = get_RNA_level_by_protein_bin(ad, gene, prot,\n",
    "                                                            scaling='zscore', \n",
    "                                                            remove_zeros=remove_zeros)\n",
    "    RNA_spliced['data_type'] = 'spliced'\n",
    "    \n",
    "    _, _, RNA_unspliced = get_RNA_level_by_protein_bin(ad, gene, prot,\n",
    "                                                            scaling='unspliced', \n",
    "                                                            remove_zeros=remove_zeros)\n",
    "    RNA_unspliced['data_type'] = 'unspliced'\n",
    "    \n",
    "    RNA_df = pd.concat([RNA_spliced,RNA_unspliced])\n",
    "    \n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots(figsize=(3,3))\n",
    "    ax = sns.boxplot(data=RNA_df, x='protein', y=gene, \n",
    "                     order=['off','on'], \n",
    "                     hue='data_type',\n",
    "                     hue_order=['unspliced','spliced'])\n",
    "    for patch in ax.artists:\n",
    "        r, g, b, a = patch.get_facecolor()\n",
    "        patch.set_facecolor((r, g, b, 0.5))\n",
    "        \n",
    "    ax = sns.stripplot(data=RNA_df, x='protein', y=gene, \n",
    "                       order=['off','on'], \n",
    "                       s=2, \n",
    "                       hue='data_type',\n",
    "                       split=True,\n",
    "                       hue_order=['unspliced','spliced'],\n",
    "                       alpha=0.6, jitter=0.08)\n",
    "\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "    test_results = add_stat_annotation(ax, data=RNA_df, x='protein', y=gene, \n",
    "                                       order=['off','on'],\n",
    "                                       hue='data_type',\n",
    "                                       box_pairs=[(('off','unspliced'),('on','unspliced')),\n",
    "                                                 (('off','spliced'),('on','spliced'))],\n",
    "                                       test='t-test_ind', text_format='star',\n",
    "                                       loc='inside', verbose=2)\n",
    "    figname = '%s/boxplot_by_splicing_%s_%s_%s.pdf' %(sc.settings.figdir, prot, gene, desc)\n",
    "    print('Saving to %s' %figname)\n",
    "    fig.savefig(figname, bbox_inches='tight')\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot_RNA_by_treatment(adata, gene):\n",
    "    ad_PBS = adata[adata.obs['assignment']=='PBS'].copy()\n",
    "    ad_KA = adata[adata.obs['assignment']=='KainicAcid'].copy()\n",
    "\n",
    "    scaling = 'zscore'\n",
    "    gene_PBS = get_feat_values(ad_PBS, gene, scaling)\n",
    "    gene_KA = get_feat_values(ad_KA, gene, scaling)\n",
    "\n",
    "    PBS_df = pd.DataFrame(list(zip(gene_PBS,len(gene_PBS)*['PBS'])),columns=[gene,'treatment'])\n",
    "    KA_df = pd.DataFrame(list(zip(gene_KA,len(gene_KA)*['KA'])),columns=[gene,'treatment'])\n",
    "    gene_df = PBS_df.append(KA_df,ignore_index=True)\n",
    "\n",
    "    from statannot import add_stat_annotation\n",
    "    fig, ax = plt.subplots(figsize=(2,2))\n",
    "    ax = sns.boxplot(data=gene_df, x='treatment', y=gene, \n",
    "                     order=['PBS','KA'], width=0.3, fliersize=1, \n",
    "                     palette=['#dcdcdc','#00CC33'])\n",
    "    # ax.set_ylim(ylims)\n",
    "    for patch in ax.artists:\n",
    "        r, g, b, a = patch.get_facecolor()\n",
    "        patch.set_facecolor((r, g, b, 0.5))\n",
    "\n",
    "    ax = sns.stripplot(data=gene_df, x='treatment', y=gene, \n",
    "                       order=['PBS','KA'], s=1, \n",
    "                       alpha=1, jitter=0.15,\n",
    "                       palette=['#696969','#00CC33'])\n",
    "    test_results = add_stat_annotation(ax, data=gene_df, x='treatment', y=gene, \n",
    "                                       order=['PBS','KA'],\n",
    "                                       box_pairs=[('PBS', 'KA')],\n",
    "                                       test='t-test_ind', text_format='star',\n",
    "                                       loc='outside', verbose=2)\n",
    "\n",
    "    figname = '%s/IEGs_boxplot_by_treatment_%s.pdf' %(sc.settings.figdir, gene)\n",
    "    print('Saving to %s' %figname)\n",
    "    fig.savefig(figname, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## linear model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_significance_dotplot_R(plot_df, feat, casestr, figsize=(6,12), circle_size='neglog_pval'): \n",
    "    from rpy2.robjects.packages import importr\n",
    "    from rpy2.robjects.conversion import localconverter\n",
    "    from rpy2.robjects import pandas2ri, numpy2ri, r, Formula\n",
    "    from rpy2.robjects.vectors import StrVector, FloatVector, ListVector\n",
    "    import rpy2.robjects as ro\n",
    "    \n",
    "    num_genes = len(set(plot_df['gene']))\n",
    "    if circle_size == 'neglog_pval': \n",
    "        circle_text = '-log10(p-value)'\n",
    "    elif circle_size == 'fraction': \n",
    "        circle_text = 'Frac. cells expressed'\n",
    "        \n",
    "    limit = max(plot_df.coefficient.abs()) * np.array([-1, 1])\n",
    "    g = (\n",
    "        ggplot(aes(x='cluster', y='gene'), data=plot_df) +\n",
    "        geom_point(aes(size=circle_size, fill='coefficient', color='significant'))+\n",
    "        scale_fill_distiller(type='div', limits=limit, name='DE coefficient') + \n",
    "        scale_color_manual(values=('#808080', '#000000')) +  # 990E1D\n",
    "        labs(size = circle_text, y='', x='', title='$%s$ %s'%(feat, casestr) ) +\n",
    "        guides(size = guide_legend(reverse=True)) +\n",
    "        theme_bw() +\n",
    "        scale_size(range = (1,10)) +\n",
    "        scale_y_discrete(drop=False) +\n",
    "        theme(\n",
    "          figure_size=figsize,\n",
    "          legend_key=element_blank(),\n",
    "          axis_text_x = element_text(rotation=45, hjust=1.),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # ggsave(g, 'figure-1-c.pdf', width=9, height=12)\n",
    "    print(g)\n",
    "    return(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pretty_volcano_simplified(plot_df, ylims=None, yticks=None, \n",
    "                                   xlims=None, xticks=None, xlabel='',\n",
    "                                   annotate=False, \n",
    "                                   annotate_list=[], color=None,\n",
    "                                   savefig=False, figdir='', filename=''): \n",
    "\n",
    "    COEFF_THRESH = 0.01 # 0.02\n",
    "    x_padding = 0.1\n",
    "    if color is None: \n",
    "        dotcolor = 'r'\n",
    "    else: \n",
    "        dotcolor = color\n",
    "        \n",
    "    fig, axes = plt.subplots(figsize=(4,4))\n",
    "#     axes = fig.axes()\n",
    "#     axes.set_position([0, 0, 8, 8])\n",
    "    axes.spines['top'].set_visible(False)\n",
    "    axes.spines['right'].set_visible(False)\n",
    "    axes.spines['bottom'].set_linewidth(1)\n",
    "    axes.spines['left'].set_linewidth(1)\n",
    "\n",
    "    plt.scatter(plot_df.loc[~plot_df['sig'],'coeff'], \n",
    "                plot_df.loc[~plot_df['sig'],'-log10p'], \n",
    "               s=1, alpha=0.5, color='#dcdcdc')\n",
    "    plt.scatter(plot_df.loc[plot_df['sig'],'coeff'], \n",
    "                plot_df.loc[plot_df['sig'],'-log10p'], \n",
    "               s=4, alpha=1, color=dotcolor)\n",
    "    \n",
    "    # determine xaxis min/max \n",
    "    if xlims==None: \n",
    "        xmax = round_decimals_up(max(np.abs(plot_df['coeff']))+0.01,2)\n",
    "        xmin = -xmax\n",
    "    else: \n",
    "        xmin, xmax = xlims\n",
    "        \n",
    "    if ylims==None: \n",
    "        ymax = roundup(max(plot_df['-log10p']))\n",
    "        ymin = 0\n",
    "    else: \n",
    "        ymin, ymax = ylims\n",
    "        \n",
    "    plt.xlim([-xmax,xmax])\n",
    "    plt.ylim([ymin,ymax])\n",
    "    \n",
    "    if yticks:\n",
    "        plt.yticks(yticks,fontsize=10)\n",
    "    if xticks: \n",
    "        plt.xticks(xticks,fontsize=10)\n",
    "    \n",
    "#     plt.xlim(xlims)\n",
    "    \n",
    "#     plt.ylim([min(yticks),max(yticks)+1])\n",
    "\n",
    "    # labels\n",
    "    if xlabel=='':\n",
    "        plt.xlabel('coefficient',fontsize=14)\n",
    "    else: \n",
    "        plt.xlabel('%s coefficient' %xlabel, fontsize=14)\n",
    "    plt.ylabel('-log10(P)',fontsize=14)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    \n",
    "    if annotate: \n",
    "        if len(annotate_list)==0:\n",
    "            ANNOT_CRITERIA = ((plot_df['sig']) & (np.abs(plot_df['coeff'])>COEFF_THRESH))\n",
    "            for idx in plot_df[ANNOT_CRITERIA].index:\n",
    "                axes.annotate(idx, (plot_df.loc[idx, 'coeff'], \n",
    "                                  plot_df.loc[idx,'-log10p']),\n",
    "                                 fontsize=10, fontweight='normal')\n",
    "        else: \n",
    "            for idx in annotate_list:\n",
    "                axes.annotate(idx, (plot_df.loc[idx, 'coeff'], \n",
    "                                  plot_df.loc[idx,'-log10p']),\n",
    "                                 fontsize=10, fontweight='normal')\n",
    "\n",
    "    if savefig: \n",
    "        if annotate: \n",
    "            figname = '%s/volcano_%s_annotated.pdf' %(figdir,filename)\n",
    "        else: \n",
    "            figname = '%s/volcano_%s_no_annotation.pdf' %(figdir,filename)\n",
    "            \n",
    "        fig.savefig(figname, bbox_inches='tight')\n",
    "        print('Saved volcano_%s' %figname)\n",
    "#     plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_volcano_plot_df(params, pvals, sig, feat, clust): \n",
    "    df_plot = pd.concat([params[feat][clust], pvals[feat][clust], sig[feat][clust]], \n",
    "                        axis=1, sort=False, keys=['coeff','pval','sig'])\n",
    "    if feat=='C(assignment)[T.PBS]': \n",
    "        df_plot['coeff'] = -df_plot['coeff']\n",
    "    df_plot['-log10p'] = -np.log10(df_plot['pval'].tolist())\n",
    "    return df_plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pretty_volcano(param_df, pval_df, feat_name, clust, annotate=False, savefig=False, figdir=''): \n",
    "    import statsmodels.stats as sms\n",
    "    pval_df['log10'] = -np.log10(list(pval_df[feat_name]))\n",
    "    pval_df['sig'], pval_df['p_adj'], _, _ = sms.multitest.multipletests(pval_df[feat_name], \n",
    "                                                                         method='fdr_bh',                                                                        \n",
    "                                                                         alpha=0.01) #bonferroni fdr_bh\n",
    "    if feat_name=='p65_norm':\n",
    "        filename='p65_norm'\n",
    "        COEFF_THRESH = 0.45\n",
    "        x_padding = 0.1\n",
    "        param_plot = param_df[feat_name]\n",
    "    elif feat_name=='cFos_norm': \n",
    "        filename='cFos_norm'\n",
    "        COEFF_THRESH = 0.2\n",
    "        x_padding = 0.1\n",
    "        param_plot = param_df[feat_name]\n",
    "    elif feat_name=='C(treatment)[T.PBS]': \n",
    "        filename='treatment'\n",
    "        COEFF_THRESH = 0.1\n",
    "        x_padding = 0.1\n",
    "        param_plot = -param_df[feat_name]\n",
    "    else: \n",
    "        filename=feat_name\n",
    "        COEFF_THRESH = 0.1\n",
    "        x_padding = 0.1\n",
    "        param_plot = param_df[feat_name]\n",
    "        \n",
    "    plt.figure(figsize=(3,3))\n",
    "    axes = plt.axes()\n",
    "    axes.spines['top'].set_visible(False)\n",
    "    axes.spines['right'].set_visible(False)\n",
    "    axes.spines['bottom'].set_linewidth(1)\n",
    "    axes.spines['left'].set_linewidth(1)\n",
    "\n",
    "    plt.scatter(param_plot.loc[~pval_df['sig']], \n",
    "                pval_df.loc[~pval_df['sig'],'log10'], \n",
    "               s=1, alpha=0.7, color='#bfbfbf')\n",
    "    plt.scatter(param_plot.loc[pval_df['sig']], \n",
    "                pval_df.loc[pval_df['sig'],'log10'], \n",
    "               s=2, alpha=0.8, color='#EB5A49')\n",
    "    \n",
    "    # determine xaxis min/max \n",
    "    xlim = max(map(abs,param_plot))+x_padding\n",
    "    plt.xlim([-xlim, xlim])\n",
    "    \n",
    "    # labels\n",
    "    plt.xlabel('%s coefficient' %filename,fontsize=12)\n",
    "    plt.ylabel('-log10(p)',fontsize=12)\n",
    "    plt.title(clust,fontsize=12)\n",
    "    \n",
    "    if annotate: \n",
    "        ANNOT_CRITERIA = ((pval_df['sig']) & (np.abs(param_plot)>COEFF_THRESH))\n",
    "        for idx in pval_df[ANNOT_CRITERIA].index:\n",
    "            axes.annotate(idx, (param_plot.loc[idx], \n",
    "                              pval_df.loc[idx,'log10']),\n",
    "                             fontsize=8, fontweight='normal')\n",
    "\n",
    "    if savefig: \n",
    "        if annotate: \n",
    "            figname = '%s/OLS_volcano_%s_%s_annotated.pdf' %(figdir,clust,filename)\n",
    "        else: \n",
    "            figname = '%s/OLS_volcano_%s_%s_no_annotation.pdf' %(figdir,clust,filename)\n",
    "        print('Saving to %s' %figname)\n",
    "        plt.savefig(figname, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_significant_heatmap(params_i, filename, min_ct=1, FC_cutoff=0.1, zmin=-3, zmax=6, fontsize=0.7):\n",
    "    from matplotlib.colors import Normalize    \n",
    "\n",
    "    class MidpointNormalize(Normalize):\n",
    "#         from matplotlib.colors import Normalize\n",
    "        def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):\n",
    "            self.midpoint = midpoint\n",
    "            Normalize.__init__(self, vmin, vmax, clip)\n",
    "\n",
    "        def __call__(self, value, clip=None):\n",
    "            # I'm ignoring masked values and all kinds of edge cases to make a\n",
    "            # simple example...\n",
    "            x, y = [self.vmin, self.midpoint, self.vmax], [0, 0.5, 1]\n",
    "            return np.ma.masked_array(np.interp(value, x, y))\n",
    "    \n",
    "    seismic_gray = make_seismic_with_nan()\n",
    "    \n",
    "    params = params_i.copy()\n",
    "    params = params[params.fillna(0).astype(bool).sum(axis=1)>=min_ct]\n",
    "    \n",
    "    if FC_cutoff:\n",
    "        filtered_df = get_filtered_df(params, FC_cutoff)\n",
    "    \n",
    "    idx_to_keep = filtered_df.index[filtered_df.fillna(0).astype(bool).sum(axis=1)>0]\n",
    "    filtered_df = filtered_df.loc[idx_to_keep]\n",
    "    \n",
    "    # get masked df\n",
    "    mask_val=-100\n",
    "    df_sub = get_mask_subbed_df(filtered_df, mask_val)\n",
    "    \n",
    "    # plot clustergram\n",
    "    sns.set(font_scale=fontsize) \n",
    "    sns.set_style('white')\n",
    "    g = sns.clustermap(df_sub, \n",
    "                       mask=df_sub==mask_val, \n",
    "                       center=0,\n",
    "                        yticklabels=df_sub.index,\n",
    "                        xticklabels=df_sub.columns,\n",
    "                        metric='euclidean',\n",
    "                        vmin=zmin, vmax=zmax, \n",
    "                       cmap=seismic_gray)\n",
    "    row_idx = g.dendrogram_row.reordered_ind\n",
    "    col_idx = g.dendrogram_col.reordered_ind\n",
    "    g.ax_row_dendrogram.set_visible(False)\n",
    "    g.ax_col_dendrogram.set_visible(False)\n",
    "#     g.savefig('%s/clustermap_%s.pdf' %(sc.settings.figdir, filename) )\n",
    "    sns.reset_orig()\n",
    "    \n",
    "    # matplotlib version\n",
    "    ordered_params = params.iloc[row_idx]\n",
    "    print(ordered_params.columns)\n",
    "    print(col_idx)\n",
    "    ordered_cols = [ordered_params.columns[i] for i in col_idx]\n",
    "    print(ordered_cols)\n",
    "    ordered_params = ordered_params[ordered_cols]\n",
    "    ordered_df = get_mask_dropped_df(ordered_params)\n",
    "    \n",
    "    fig,ax = plt.subplots(figsize=(2,ordered_df.shape[0]*(1/10))) \n",
    "    heatmap = ax.pcolor(ordered_df, cmap=seismic_gray, norm=MidpointNormalize(midpoint=0), \n",
    "                  vmin=zmin, vmax=zmax, linewidth=2) \n",
    "    ax.patch.set(facecolor='#d3d3d3', edgecolor='black')\n",
    "    ax.set_xticks(np.arange(ordered_params.shape[1])+0.5, minor=False)\n",
    "    ax.set_xticklabels(ordered_params.columns, rotation=90, fontsize=6)\n",
    "    ax.set_yticks(np.arange(0,ordered_params.shape[0],1)+0.5, minor=False)\n",
    "    ax.set_yticklabels(ordered_params.index, fontsize=5.5)\n",
    "#     fig.savefig('%s/heatmap_clustered_%s.pdf' %(sc.settings.figdir, filename), bbox_inches='tight')\n",
    "\n",
    "    return filtered_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feat_coefficients_PBS_KA(feat, params_PBS, params_KA, pvals_PBS, pvals_KA, \n",
    "                                  sig_PBS, sig_KA, GENE_TO_PLOT=None,\n",
    "                                  x_sig_lim=None, y_sig_lim=None):\n",
    "    prot_name = '%s_nCLR' %feat\n",
    "    \n",
    "    params = combine_df_sig([params_PBS, params_KA], prot_name, ['PBS','KA'])\n",
    "    pvals = combine_df_sig([pvals_PBS, pvals_KA], prot_name, ['PBS','KA'])        \n",
    "    sigs = combine_df_sig([sig_PBS, sig_KA], prot_name, ['PBS','KA'])\n",
    "    \n",
    "    # remove sigs that don't meet params threshold\n",
    "    if x_sig_lim != None:\n",
    "        print('limiting PBS sigs')\n",
    "        sigs.loc[(np.abs(params['PBS'])<x_sig_lim), 'PBS'] = False\n",
    "    if y_sig_lim != None:\n",
    "        print('limiting KA sigs')\n",
    "        sigs.loc[(np.abs(params['KA'])<y_sig_lim), 'KA'] = False\n",
    "\n",
    "    sigs['combined'] = 'neither'\n",
    "    sigs.loc[((sigs['PBS']==False) & (sigs['KA']==True)), 'combined'] = 'KA'\n",
    "    sigs.loc[((sigs['PBS']==True) & (sigs['KA']==False)), 'combined'] = 'PBS'\n",
    "    sigs.loc[((sigs['PBS']==True) & (sigs['KA']==True)), 'combined'] = 'both'\n",
    "    \n",
    "    fig = plt.figure(figsize=(5,5))\n",
    "    axes = plt.gca()\n",
    "    axes.spines['top'].set_visible(False)\n",
    "    axes.spines['right'].set_visible(False)\n",
    "    \n",
    "    if prot_name=='cFos_nCLR':\n",
    "        tx = [-0.1,-0.05,0,0.05,0.1]\n",
    "        xlims = [-0.1, 0.1]\n",
    "        ylims = [-0.075, 0.12]\n",
    "    elif prot_name=='p65_nCLR':\n",
    "        tx = [-0.4,-0.3,-0.2,-0.1,0,0.1,0.2,0.3,0.4]\n",
    "        xlims = [-0.2, 0.4]\n",
    "        ylims = [-0.1, 0.2]\n",
    "    elif prot_name=='PU1_nCLR': \n",
    "        tx = [-0.1,-0.05,0,0.05,0.1]\n",
    "        xlims = [-0.12, 0.12]\n",
    "        ylims = [-0.075, 0.075]\n",
    "    elif prot_name=='NeuN_nCLR':\n",
    "        tx = [-0.4,-0.2,0,0.2,0.4]\n",
    "        xlims = [-0.6, 0.3]\n",
    "        ylims = [-0.4, 0.3]\n",
    "    \n",
    "    axes.set_xticks(tx)\n",
    "    axes.set_xticklabels(labels=tx, fontsize=10)\n",
    "    axes.set_xlim(xlims)\n",
    "\n",
    "    axes.set_yticks(tx)\n",
    "    axes.set_yticklabels(labels=tx, fontsize=10)\n",
    "    axes.set_ylim(ylims)\n",
    "    \n",
    "    plt.scatter(data = params.loc[sigs['combined']=='neither'], \n",
    "                x='PBS',y='KA', s=2, \n",
    "                axes=axes, color='#dcdcdc') #bfbfbf\n",
    "    plt.scatter(data = params.loc[sigs['combined']=='PBS'], \n",
    "                x='PBS',y='KA', s=9,\n",
    "#                 s=-np.log10(pvals.loc[sigs['combined']=='PBS','PBS'].tolist()),\n",
    "                axes=axes, color='#708a97')\n",
    "    plt.scatter(data = params.loc[sigs['combined']=='KA'], \n",
    "                x='PBS',y='KA', s=9,\n",
    "#                 s=-np.log10(pvals.loc[sigs['combined']=='KA','KA'].tolist()),\n",
    "                axes=axes, color='#00CC33')\n",
    "    # use the bigger p value (to be more conservative)\n",
    "    plt.scatter(data = params.loc[sigs['combined']=='both'], \n",
    "                x='PBS',y='KA', s=9,\n",
    "#                 s=-np.log10(pvals.loc[sigs['combined']=='both'].min(axis=1).tolist()), \n",
    "                axes=axes, color='k')\n",
    "    plt.axvline(0, color='k', linewidth=0.8)\n",
    "    plt.axhline(0, color='k', linewidth=0.8)\n",
    "    if x_sig_lim != None:\n",
    "        plt.axvline(x_sig_lim, color='#ff4500', linestyle='--', linewidth=0.5, \n",
    "                   alpha=0.8)\n",
    "        plt.axvline(-x_sig_lim, color='#ff4500', linestyle='--', linewidth=0.5,\n",
    "                   alpha=0.8)\n",
    "    if y_sig_lim != None:\n",
    "        plt.axhline(y_sig_lim, color='#ff4500', linestyle='--', linewidth=0.5, \n",
    "                   alpha=0.8)\n",
    "        plt.axhline(-y_sig_lim, color='#ff4500', linestyle='--', linewidth=0.5,\n",
    "                   alpha=0.8)\n",
    "\n",
    "    plt.xlabel('%s coefficient (PBS)' %feat, fontsize=12)\n",
    "    plt.ylabel('%s coefficient (KA)' %feat, fontsize=12)\n",
    "\n",
    "    if GENE_TO_PLOT is not None:\n",
    "        if type(GENE_TO_PLOT) is list: \n",
    "            for gene in GENE_TO_PLOT:\n",
    "                axes.annotate(gene, (params.loc[gene,'PBS'], \n",
    "                              params.loc[gene,'KA']),\n",
    "                             fontsize=10, fontweight='medium')\n",
    "        else: \n",
    "            axes.annotate(GENE_TO_PLOT, (params.loc[GENE_TO_PLOT,'PBS'], \n",
    "                          params.loc[GENE_TO_PLOT,'KA']),\n",
    "                         fontsize=10, fontweight='medium')\n",
    "    figname = '%s/%s.pdf' %(sc.settings.figdir, 'DEG_coeff_scatter_PBSvsKA_mixedlm_regularized_%s' %feat)\n",
    "    print('Saving to %' %figname)\n",
    "    fig.savefig(figname, bbox_inches='tight')\n",
    "#     plt.close(fig)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def params_linear_fit(params): \n",
    "    from scipy import stats\n",
    "    params_copy = params.astype(float)\n",
    "    params_copy.dropna(inplace=True)\n",
    "    \n",
    "    xvals = params_copy['PBS']\n",
    "    yvals = params_copy['KA']\n",
    "    m,b = np.polyfit(xvals, yvals, 1)\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(xvals, yvals)\n",
    "    print('Slope %.4f \\t R^2 %.4f \\t pval %.6f' %(slope, r_value**2, p_value) )\n",
    "    print(r_value**2, p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_CITE_gene_scatter(ad, gene, cite, scaling='lognorm', remove_zeros=False, \n",
    "                           savefig=False, figdir='', fignote='', plotline=False): \n",
    "    \n",
    "    if remove_zeros: \n",
    "        if scaling=='lognorm' or scaling=='zscore': \n",
    "            feat_type='counts'\n",
    "        elif scaling=='spliced': \n",
    "            feat_type='spliced_counts'\n",
    "        elif scaling=='unspliced': \n",
    "            feat_type='unspliced_counts'\n",
    "        else: \n",
    "            feat_type=scaling\n",
    "        ad = ad[ad[:,gene].layers[feat_type].toarray()>0].copy()\n",
    "    \n",
    "    plt.figure(figsize=(3,3))\n",
    "    axes = plt.axes()\n",
    "\n",
    "    axes.spines['top'].set_visible(False)\n",
    "    axes.spines['right'].set_visible(False)\n",
    "    axes.spines['bottom'].set_linewidth(1)\n",
    "    axes.spines['left'].set_linewidth(1)\n",
    "    axes.set_xlabel(xlabel=gene,fontsize=12)\n",
    "    axes.set_ylabel(ylabel=cite,fontsize=12)\n",
    "    axes.figure.set_size_inches(3,3)\n",
    "\n",
    "    x_list = get_feat_values(ad, gene, scaling)\n",
    "    y_list = get_feat_values(ad, cite, scaling)\n",
    "\n",
    "    plt.scatter(x_list+np.random.uniform(low=-0.005,high=0.005,size=len(x_list)), y_list,\n",
    "                 s=4,alpha=0.7,color='#bcbcbc',axes=axes) \n",
    "    plt.xlabel(gene,fontsize=12)\n",
    "    plt.ylabel(cite,fontsize=12)\n",
    "\n",
    "    X_V, Y_V = get_linear_regression_stats(ad, gene, cite, scaling)\n",
    "    \n",
    "    if plotline: \n",
    "        plt.plot(X_V, Y_V, color='k', linewidth=0.5)\n",
    "\n",
    "    if savefig: \n",
    "        if sc.settings.figdir=='': \n",
    "            print('Please enter valid figdir')\n",
    "            return\n",
    "        else: \n",
    "            plt.savefig('%s/scatter_%s_%s_%s.pdf' %(figdir, gene, cite, fignote),\n",
    "                                                bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dotplot tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_df(df):\n",
    "    mask_val=-100\n",
    "    df_sub = get_mask_subbed_df(df, mask_val)\n",
    "    g = sns.clustermap(df_sub, \n",
    "                            mask=df_sub==mask_val, \n",
    "                           metric='rogerstanimoto',\n",
    "                            yticklabels=df.index,\n",
    "                            xticklabels=df.columns,)\n",
    "    row_idx = g.dendrogram_row.reordered_ind\n",
    "    col_idx = g.dendrogram_col.reordered_ind\n",
    "    plt.close()\n",
    "    return row_idx, col_idx\n",
    "\n",
    "def get_ordered_dotplot_df(params, pvals, sig, frac, feat, THRESH, COEFF_THRESH=0): \n",
    "    dotplot_df, df = make_dotplot_df(params, pvals, sig, frac, feat, THRESH, COEFF_THRESH=COEFF_THRESH)\n",
    "\n",
    "    rows, cols = cluster_df(df)\n",
    "    dotplot_df['gene'] = dotplot_df['gene'].astype('category')\n",
    "    dotplot_df.gene.cat.reorder_categories(new_categories=df.index[rows], inplace=True)\n",
    "    return dotplot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_volcano_plot_df_total_model(params, pvals, sig, feat): \n",
    "    df_plot = pd.concat([params[feat], pvals[feat], sig[feat]], \n",
    "                        axis=1, sort=False, keys=['coeff','pval','sig'])\n",
    "#     if feat=='C(assignment)[T.PBS]': \n",
    "#         df_plot['coeff'] = -df_plot['coeff']\n",
    "    df_plot['-log10p'] = -np.log10(df_plot['pval'].tolist())\n",
    "    return df_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cross correlation tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_pvalues(df):\n",
    "    df = df.dropna()._get_numeric_data()\n",
    "    dfcols = pd.DataFrame(columns=df.columns)\n",
    "    pvalues = dfcols.transpose().join(dfcols, how='outer')\n",
    "    for r in df.columns:\n",
    "        for c in df.columns:\n",
    "            pvalues[r][c] = round(pearsonr(df[r], df[c])[1], 4)\n",
    "    return pvalues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_coefficients(df, feat, params_unspliced, params_spliced): \n",
    "    df['coeff'] = 0\n",
    "    for idx, row in df.iterrows():\n",
    "        if row['list']=='unspliced':\n",
    "            df.loc[idx,'coeff'] = params_unspliced.loc[row['gene'],feat]\n",
    "        elif row['list']=='spliced':\n",
    "            df.loc[idx,'coeff'] = params_spliced.loc[row['gene'],feat]\n",
    "        elif row['list']=='both': \n",
    "            unsp = params_unspliced.loc[row['gene'],feat]\n",
    "            sp = params_spliced.loc[row['gene'],feat]\n",
    "            if np.sign(unsp)==np.sign(sp):\n",
    "                df.loc[idx,'coeff'] = np.median([unsp,sp])\n",
    "            else: \n",
    "                print('WARNING: opposite signs for %s' %row['gene'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_coefficients_cluster(sig_dict, feat, params_unspliced, params_spliced): \n",
    "    for clust in sig_dict.keys(): \n",
    "        if sig_dict[clust].shape[0]>0: \n",
    "            sig_dict[clust]['coeff'] = 0\n",
    "            for idx, row in sig_dict[clust].iterrows():\n",
    "                if row['list']=='unspliced':\n",
    "                    sig_dict[clust].loc[idx,'coeff'] = params_unspliced[feat].loc[row['gene'],clust]\n",
    "                elif row['list']=='spliced':\n",
    "                    df.loc[idx,'coeff'] = params_spliced[feat].loc[row['gene'],clust]\n",
    "                elif row['list']=='both': \n",
    "                    unsp = params_unspliced[feat].loc[row['gene'],clust]\n",
    "                    sp = params_spliced[feat].loc[row['gene'],clust]\n",
    "                    if np.sign(unsp)==np.sign(sp):\n",
    "                        df.loc[idx,'coeff'] = np.median([unsp,sp])\n",
    "                    else: \n",
    "                        print('WARNING: opposite signs for %s' %row['gene'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def DEG_graph(ad, sig_genes_df, figstr, thresh=0.08, color_by='all', \n",
    "#               data_mode='zscore', color_mode='fraction', random_seed=42): \n",
    "#     import matplotlib as mpl\n",
    "\n",
    "#     P_THRESH = 0.05\n",
    "    \n",
    "#     if color_by=='all': \n",
    "#         ad_col = ad\n",
    "#     elif color_by=='neuron':\n",
    "#         ad_col = ad_neuron\n",
    "#     else: \n",
    "#         if type(color_by) is list: \n",
    "#             ad_col = ad[ad.obs['annot'].isin(color_by)]\n",
    "#         else: \n",
    "#             ad_col = ad[ad.obs['annot'].isin([color_by])]\n",
    "#     add_gene_frac(ad_col)   \n",
    "\n",
    "#     DEG_corr, DEG_pval = get_significant_corr(ad, sig_genes_df, data_mode)\n",
    "#     DEG_sig_corr = DEG_corr[DEG_pval<=P_THRESH]\n",
    "\n",
    "#     # Transform it in a links data frame (3 columns only):\n",
    "#     links = DEG_sig_corr.stack().reset_index()\n",
    "#     links.columns = ['Gene1','Gene2','corr']\n",
    "    \n",
    "#     # Keep only correlation over a threshold and remove self correlation (cor(A,A)=1)\n",
    "#     links_filtered = links.loc[ (links['corr'] > thresh) & (links['Gene1'] != links['Gene2'])]\n",
    "    \n",
    "#     import networkx as nx\n",
    "#     G=nx.from_pandas_edgelist(links_filtered, 'Gene1', 'Gene2')\n",
    "    \n",
    "#     # color by fraction expressed\n",
    "#     if color_mode=='fraction': \n",
    "#         node_vals = ad_col.var['gene_frac'].loc[list(G.nodes)]\n",
    "#         cmap = 'YlGn'\n",
    "#         vmin= 0\n",
    "#         vmax= 0.8\n",
    "#         nodescale = 1200\n",
    "#         node_size = nodescale*node_vals\n",
    "#     elif color_mode=='coeff': \n",
    "#         vmin = -0.15\n",
    "#         vmax = 0.15\n",
    "#         df_color = sig_genes_df.copy()\n",
    "        \n",
    "#         df_color.set_index('gene', inplace=True)\n",
    "#         df_color = df_color[df_color.index.isin(list(G.nodes))]\n",
    "#         df_color = df_color.reindex(G.nodes())\n",
    "#         node_vals = df_color['coeff']\n",
    "#         cmap = 'coolwarm'\n",
    "#         node_size = 350\n",
    "        \n",
    "#     # node edge color by gene type\n",
    "#     gene_color_dict = dict(zip(sig_genes_df['gene'], sig_genes_df['color']))\n",
    "#     splice_type_color = [gene_color_dict[g] for g in list(G.nodes)]\n",
    "        \n",
    "#     plt.figure(figsize=[10,10])\n",
    "# #     np.random.seed(42)\n",
    "#     np.random.seed(random_seed)\n",
    "#     nx.draw_kamada_kawai(G, with_labels=True,  \n",
    "#                          edge_color='#D3D3D3', # edge\n",
    "#                          width=2, # edge\n",
    "#                          edgecolors=splice_type_color, # node\n",
    "#                          linewidths=2.5,  # node\n",
    "#                          font_size=14, # node\n",
    "#                          node_color=node_vals,  # node\n",
    "#                          node_size=node_size, # node\n",
    "#                          alpha=0.8, \n",
    "#                          vmin=vmin,\n",
    "#                          vmax=vmax,\n",
    "#                          cmap=cmap)\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig('%s/DEG_graph_%0.3f_%s.pdf' %(sc.settings.figdir, thresh, figstr), bbox_inches='tight')\n",
    "    \n",
    "#     return DEG_sig_corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DEG_corr_clustermap(df_corr, figstr, thresh=0.08, savefig=True):\n",
    "    plt.figure(figsize=[10,10])\n",
    "    df_corr[df_corr<thresh]=0\n",
    "    df_corr[np.isnan(df_corr)]=0\n",
    "    df_corr[np.isinf(df_corr)]=0\n",
    "    off_diag = df_corr.sum()>1\n",
    "    df_off_diag = df_corr.loc[off_diag, off_diag]\n",
    "    sns.set(font_scale=0.8)\n",
    "    f = sns.clustermap(df_off_diag, \n",
    "                   xticklabels=df_off_diag.index, \n",
    "                   yticklabels=df_off_diag.columns,\n",
    "                   cmap='coolwarm',\n",
    "                  vmax=0.5)\n",
    "    if savefig: \n",
    "        f.savefig('%s/DEG_corr_clustermap_%s_%0.2f.pdf' %(sc.settings.figdir, figstr, thresh), bbox_inches='tight')\n",
    "    sns.reset_orig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_corr(ad, params, sig, cell_type, interaction=False, corr_thresh=0.05): \n",
    "#     cell_type = 'EX_neuron'\n",
    "    cFos = list(sig['cFos_nCLR'][sig['cFos_nCLR'][cell_type]].index)\n",
    "    p65 = list(sig['p65_nCLR'][sig['p65_nCLR'][cell_type]].index)\n",
    "    \n",
    "    if interaction: \n",
    "        cFos_p65 = list(sig['cFos_nCLR:p65_nCLR'][sig['cFos_nCLR:p65_nCLR'][cell_type]].index)\n",
    "        DEGs = list(set(cFos + p65 + cFos_p65))\n",
    "        \n",
    "        prot_list = ['NeuN','PU1','p65','cFos','cFos_nCLR:p65_nCLR','cFos_nCLR:NeuN_nCLR','p65_nCLR:NeuN_nCLR']\n",
    "        color_list = ['PiYG_r','PiYG_r','PiYG_r','PiYG_r','PiYG_r','PiYG_r','PiYG_r']\n",
    "    else: \n",
    "        DEGs = list(set(cFos + p65))\n",
    "        \n",
    "        prot_list = ['NeuN','PU1','p65','cFos']\n",
    "        color_list = ['PiYG_r','PiYG_r','PiYG_r','PiYG_r']\n",
    "\n",
    "    genes_color = gene_feat_colors_cluster(sig, params, DEGs, [cell_type], \n",
    "                                           proteins=prot_list, colors=color_list)\n",
    "\n",
    "\n",
    "    df_corr = get_corr_df(ad[ad.obs['annot']==cell_type], DEGs)\n",
    "    \n",
    "    return df_corr, genes_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustermap_corr_DEGs(DEG_corr, genes_color, figstr='', vmin=-0.5, vmax=0.5, savefig=False):\n",
    "    from matplotlib.patches import Rectangle\n",
    "    \n",
    "    sns.set(font_scale=0.8)\n",
    "    g = sns.clustermap(DEG_corr, \n",
    "                    xticklabels=[], \n",
    "                    yticklabels=DEG_corr.index,\n",
    "                    col_colors=genes_color,\n",
    "                    dendrogram_ratio=0.08, \n",
    "                    colors_ratio=0.025,\n",
    "                    vmin=vmin, vmax=vmax, \n",
    "                    cmap='bwr', \n",
    "                    cbar_pos=[1,0.6,0.02,0.1])\n",
    "    g.ax_col_dendrogram.set_visible(False)\n",
    "    g.ax_row_dendrogram.set_visible(False)\n",
    "    ax = g.ax_heatmap\n",
    "    ax.axhline(y=0, color='k',linewidth=2)\n",
    "    ax.axvline(x=0, color='k',linewidth=2)\n",
    "    figname = '%s/modules_cross_corr_cluster_%s.pdf' %(sc.settings.figdir, figstr)\n",
    "    if savefig: \n",
    "        print('Saving to %s' %figname)\n",
    "        plt.savefig(figname, bbox_inches='tight')\n",
    "    sns.reset_orig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_genes_per_module(ax, top_scores, top_genes): \n",
    "    \n",
    "    ax.barh(range(len(top_genes)), top_scores, color='#bfbfbf')\n",
    "    ax.set_xlabel('Correlation')\n",
    "    ax.set_yticks(range(len(top_genes)))\n",
    "    ax.set_yticklabels(top_genes, rotation=0)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "#     ax.spines['bottom'].set_visible(False)\n",
    "    ax.invert_yaxis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap_module_genes(ad, mod_genes): \n",
    "    blah = []\n",
    "    for k, v in mod_genes.items(): \n",
    "        blah.extend(list(v))\n",
    "\n",
    "    DEG_corr_heatmap = get_corr_df(ad, blah)\n",
    "\n",
    "    sns.set(font_scale=0.4)\n",
    "    sns.heatmap(DEG_corr_heatmap, \n",
    "                    xticklabels=DEG_corr_heatmap.index,\n",
    "                    yticklabels=DEG_corr_heatmap.index,\n",
    "                   vmin=-0.3, vmax=0.3, \n",
    "                   cmap='bwr')\n",
    "    sns.reset_orig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def module_score_treatment_boxplot(ad, module, color_dict, figstr=''): \n",
    "    from statannot import add_stat_annotation\n",
    "    df = ad.obs\n",
    "    fig, ax = plt.subplots(figsize=(2,3))\n",
    "    ax = sns.boxplot(data=df, x='assignment', y=module, \n",
    "                     order=['PBS','KainicAcid'], width=0.3,\n",
    "                     fliersize=0,\n",
    "                     palette=color_dict)\n",
    "\n",
    "    for patch in ax.artists:\n",
    "        r, g, b, a = patch.get_facecolor()\n",
    "        patch.set_facecolor((r, g, b, 0.5))\n",
    "        \n",
    "    ax = sns.stripplot(data=df, x='assignment', y=module, \n",
    "                       order=['PBS','KainicAcid'], s=1, \n",
    "                       alpha=0.5, jitter=0.08,\n",
    "                       palette=color_dict)\n",
    "    test_results = add_stat_annotation(ax, data=df, \n",
    "                                       x='assignment', y=module, \n",
    "                                       order=['PBS','KainicAcid'],\n",
    "                                       box_pairs=[('PBS', 'KainicAcid')],\n",
    "                                       test='t-test_ind', text_format='star',\n",
    "                                       loc='outside', verbose=2)\n",
    "    figname = '%s/module_score_by_treatment_boxplot_%s.pdf' %(sc.settings.figdir, figstr)\n",
    "    print('Saving to %s' %figname)\n",
    "    fig.savefig(figname, bbox_inches='tight')\n",
    "    \n",
    "def module_score_treatment_violinplot(ad, module, color_dict, figstr=''): \n",
    "    from statannot import add_stat_annotation\n",
    "    df = ad.obs\n",
    "    fig, ax = plt.subplots(figsize=(2,2))\n",
    "    ax = sns.violinplot(data=df, x='assignment', y=module, \n",
    "                     order=['PBS','KainicAcid'], width=0.3,\n",
    "                     scale='width', saturation=0.7,\n",
    "                     palette=color_dict)\n",
    "    for patch in ax.artists:\n",
    "        r, g, b, a = patch.get_facecolor()\n",
    "        patch.set_facecolor((r, g, b, 0.5))\n",
    "        \n",
    "#     ax = sns.stripplot(data=df, x='assignment', y=module, \n",
    "#                        order=['PBS','KainicAcid'], s=0.5, \n",
    "#                        alpha=0.5, \n",
    "#                        palette=color_dict)\n",
    "    ax.set(xlabel=None)\n",
    "    ax.set(xticklabels=['PBS','KA'])\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    figname = '%s/module_score_by_treatment_violinplot_%s.pdf' %(sc.settings.figdir, figstr)\n",
    "    print('Saving to %s' %figname)\n",
    "    fig.savefig(figname, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GO analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_GO_query(gene_list, species, db_to_keep='all'): \n",
    "    if db_to_keep=='all': \n",
    "        db_to_keep = ['GO:BP', 'GO:MF', 'KEGG', 'REAC', 'TF']\n",
    "    GO_df = sc.queries.enrich(gene_list, org=species)\n",
    "    GO_df = GO_df[GO_df['significant']==True]\n",
    "    GO_df = GO_df[GO_df['source'].isin(db_to_keep)]\n",
    "    return GO_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig_genes_GO_query(sig, params, variate, clust_lim=1000):\n",
    "    sig_genes = get_sig_gene_list(sig,params,variate)\n",
    "    GO_results = pd.DataFrame([],columns=['cluster','source','name','p_value','description','native','parents'])\n",
    "    \n",
    "    idx_ct = 0\n",
    "    clusters = sig[variate].columns\n",
    "    for clust in clusters: \n",
    "        clust_ct = 0\n",
    "        if len(sig_genes[clust])>1: \n",
    "            GO_df = parse_GO_query(sig_genes[clust],'mmusculus',['GO:BP','KEGG'])\n",
    "            if len(GO_df)>0:\n",
    "                for index, row in GO_df.iterrows():\n",
    "                    if clust_ct<clust_lim:\n",
    "                        GO_row = pd.DataFrame({'cluster':clust,'source':row['source'],\n",
    "                                             'name':row['name'],'p_value':row['p_value'],\n",
    "                                             'description':row['description'], \n",
    "                                             'native':row['native'], 'parents':[row['parents']]},\n",
    "                                                index=[idx_ct])\n",
    "                        clust_ct+=1\n",
    "                        idx_ct+=1\n",
    "                        GO_results = pd.concat([GO_results, GO_row])\n",
    "    return GO_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_GO_terms(df,alpha,filename,colormap='#d3d3d3',xlims=[0,5]): \n",
    "    \n",
    "    # add color column\n",
    "    if colormap != '#d3d3d3': \n",
    "        df['color'] = df['cluster'].map(colormap)\n",
    "        color=df['color']\n",
    "    else: \n",
    "        color=colormap\n",
    "    \n",
    "    df = df.loc[df['p_value']<=alpha]\n",
    "    \n",
    "    fig_height = df.shape[0]*(1/10)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(3,fig_height))\n",
    "    y_pos = np.arange(df.shape[0])\n",
    "    log10p = -np.log10(df['p_value'].tolist())\n",
    "    df['-log10p'] = log10p\n",
    "    \n",
    "    sns.reset_orig()\n",
    "    ax.barh(y_pos, log10p, align='center', color=color)\n",
    "    ax.set_yticks(y_pos)\n",
    "#     ax.set_yticklabels(df['native']+':'+df['name'],fontsize=6)\n",
    "    ax.set_yticklabels(df['name'],fontsize=6)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xlabel('-log10(P)')\n",
    "    ax.set_xlim(xlims)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_linewidth(1)\n",
    "#     plt.show()\n",
    "    figname = '%s/GO_hbar_%s.pdf' %(sc.settings.figdir, filename)\n",
    "    print('Saving to %s' %figname)\n",
    "    fig.savefig(figname, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_three_state_cell_cycle(ad): \n",
    "    # load cell cycle genes - 3 phases, from Seurat tutorial\n",
    "    seurat_cc_genes = [x.strip() for x in open('./regev_lab_cell_cycle_genes.txt')]\n",
    "    s_genes = seurat_cc_genes[:43]\n",
    "    g2m_genes = seurat_cc_genes[43:]\n",
    "    seurat_cc_genes = [x for x in seurat_cc_genes if x in ad.var_names]\n",
    "    \n",
    "    # make a var field for True/False cell_cycle_genes\n",
    "    ad.var['cell_cycle'] = False\n",
    "    ad.var.loc[seurat_cc_genes, 'cell_cycle'] = True\n",
    "    \n",
    "    # score\n",
    "    sc.tl.score_genes_cell_cycle(ad, s_genes=s_genes, g2m_genes=g2m_genes)\n",
    "    \n",
    "    sc.pl.scatter(ad,x='S_score',y='G2M_score',color='phase')\n",
    "    \n",
    "    adata_cc_genes = ad[:, seurat_cc_genes]\n",
    "    sc.pp.scale(adata_cc_genes, max_value=10)\n",
    "    sc.tl.pca(adata_cc_genes)\n",
    "    sc.pl.pca_scatter(adata_cc_genes, color=['phase','assignment'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "331.97922px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
